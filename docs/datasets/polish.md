# ğŸ‡µğŸ‡± Polish

This is an overview of all the datasets used in the Polish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### PolEmo2
This dataset was published in [this paper](https://aclanthology.org/K19-1092/) and consists of Polish online reviews from the medicine and hotels domains, annotated for sentiment. Each review is labelled as positive, negative, neutral, or ambiguous. We have filtered out the ambiguous samples.

The original full dataset consists of 6,573 / 823 / 820 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original splits. For the test split, we use all available test samples and supplement with additional samples from the training set to reach 2,048 samples in total.

The distribution of sentiment labels across the combined splits is as follows:
- **Negative**: 1,592 samples
- **Positive**: 1,119 samples
- **Neutral**: 617 samples

Here are a few examples from the training split:

```json
{
    "text": "Stary , bardzo zaniedbany hotel , obsluga czesto nie w humorze nie wykluczajac wlasciciela hotelu . Sniadania malo urozmaicone , powtarzajace sie przez caly tydzien dwa rodzaje byle jakiej wedliny , jednego rodzaju zoltego sera i jajecznicy ze sproszkowanych jajek . Obiadokolacja bardzo pozno 19 . 30 . Dla malych dzieci i zmeczonych narciarzy stanowczo za pozno . Napewno odwiedze Livignio , ale nigdy wiecej hotel Europa .",
    "label": "negative"
}
```
```json
{
    "text": "Arkadiusz Miszuk zostaÅ‚ powoÅ‚any na stanowisko prezesa , zaÅ› Dariusz Rutowicz na stanowisko wiceprezesa , gieÅ‚dowej spÃ³Å‚ki hotelowej Interferie SA , poinformowaÅ‚a spÃ³Å‚ka w komunikacie z 16 marca : â€ ZarzÄ…d spÃ³Å‚ki Interferie INTERFERIE S . A . w Lubinie , informuje iÅ¼ Rada Nadzorcza SpÃ³Å‚ki na posiedzeniu w dniu 16 . 03 . 2012 roku odwoÅ‚aÅ‚a ze skÅ‚adu ZarzÄ…du : 1 ) Pana Adama Milanowskiego , 2 ) Pana RadosÅ‚awa BesztygÄ™ . JednoczeÅ›nie ZarzÄ…d INTERFERIE S . A . w Lubinie , informuje iÅ¼ w dniu 16 . 03 . 2012 roku Rada Nadzorcza SpÃ³Å‚ki powoÅ‚aÅ‚a w skÅ‚ad ZarzÄ…du : 1 ) Pana Arkadiusza Miszuka - na stanowisko Prezesa ZarzÄ…du , 2 ) Pana Dariusza Rutowicza - na stanowisko Wiceprezesa ZarzÄ…du .",
    "label": "neutral"
}
```
```json
{
    "text": "Hotel znajduje siÄ™ w idealnym miejscu dla fanÃ³w pieszych wycieczek . Z dala od zgieÅ‚ku KrupÃ³wek - blisko szlakÃ³w wychodzÄ…cych w gÃ³ry . Pokoje przestronne i czyste . ObsÅ‚uga bardzo miÅ‚a . Basen jest aczkolwiek swoim urokiem nie zachwyca . Bardzo bogate i smaczne Å›niadania . RÃ³wnieÅ¼ jedzenie w restauracji jest naprawdÄ™ godne polecenia . Byli Å›my goÅ›Ä‡mi hotelu juÅ¼ dwa razy za rÃ³wno jako para jaki i rodzina z dzieÄ‡mi i za kaÅ¼dym razem byli Å›my zadowoleni .",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Liczba przykÅ‚adÃ³w few-shot: 12
- Prefiks promptu:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ dokumenty i ich sentyment, ktÃ³ry moÅ¼e byÄ‡ 'pozytywny', 'neutralny' lub 'negatywny'.
  ```
- Szablon podstawowy promptu:
  ```
  Dokument: {text}
  Sentyment: {label}
  ```
- Szablon promptu instrukcyjnego:
  ```
  Dokument: {text}

  Klasyfikuj sentyment w dokumencie. Odpowiedz z 'pozytywny', 'neutralny' lub 'negatywny', i nic wiÄ™cej.
  ```
- Label mapping:
    - `positive` â¡ï¸ `positive`
    - `neutral` â¡ï¸ `neutral`
    - `negative` â¡ï¸ `negative`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset polemo2
```


## Named Entity Recognition

### KPWr-NER

This dataset was published in [this paper](https://aclanthology.org/L12-1574/) and is part of the KPWr (KrakÃ³wPoland WrocÅ‚aw) corpus - a free Polish corpus annotated with various types of linguistic entities including named entities. The corpus was created to serve as training and testing material for Machine Learning algorithms and is released under a Creative Commons licence. The named entity annotations include persons, locations, organizations, and miscellaneous entities, which are mapped to standard BIO format labels.

The original dataset uses the train and test splits from the source corpus. The original data train split has 13,959 samples and test split has 4,323 samples. The validation split is created from the original training split. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The train and validation splits are subsets of the original training split, while the test split is a subset of the original test split.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Rublowka', '(', 'ros', '.', 'Ğ ÑƒĞ±Ğ»Ñ‘Ğ²ĞºĞ°', ')', 'â€“', 'potoczna',
       'nazwa', 'zachodniego', 'przedmieÅ›cia', 'Moskwy', '.'], dtype=object),
  "labels": array(['B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Wiele', 'z', 'nich', 'zebraÅ‚', 'w', 'tomie', 'Cymelium', '(',
       '1978', ')', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Raul', 'Lozano', ':', 'Å»eby', 'nie', 'byÅ‚o', ',', 'Å¼e',
       'faworyzuje', 'mistrza', 'Polski', 'w', 'siatkÃ³wce', ',', 'nie',
       'przyjechaÅ‚', 'na', 'mecze', 'rozgrywane', 'w', 'BeÅ‚chatowie', '.'],
      dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ zdania i sÅ‚owniki JSON z nazwanymi jednostkami wystÄ™pujÄ…cymi w danym zdaniu.
  ```
- Base prompt template:
  ```
  Zdanie: {text}
  Nazwane jednostki: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Zdanie: {text}

  Zidentyfikuj nazwane jednostki w zdaniu. PowinieneÅ› wypisaÄ‡ to jako sÅ‚ownik JSON z kluczami 'osoba', 'lokalizacja', 'organizacja' i 'rÃ³Å¼ne'. WartoÅ›ci powinny byÄ‡ listami nazwanych jednostek tego typu, dokÅ‚adnie tak jak pojawiajÄ… siÄ™ w zdaniu.
  ```
- Label mapping:
    - `B-PER` â¡ï¸ `osoba`
    - `I-PER` â¡ï¸ `osoba`
    - `B-LOC` â¡ï¸ `lokalizacja`
    - `I-LOC` â¡ï¸ `lokalizacja`
    - `B-ORG` â¡ï¸ `organizacja`
    - `I-ORG` â¡ï¸ `organizacja`
    - `B-MISC` â¡ï¸ `rÃ³Å¼ne`
    - `I-MISC` â¡ï¸ `rÃ³Å¼ne`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset kpwr-ner
```


## Linguistic Acceptability

### ScaLA-pl

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Polish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Polish-PDB) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 22,152 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "PapierowÄ… Å›mierÄ‡ zafundowaliÅ›my zafundowali Å›my juÅ¼ kilku osobom.",
    "label": "correct"
}
```
```json
{
    "text": "To tylko maÅ‚y krok; znam doskonale jego rozmiar; jestem Å›wiadomy, Å¼e polityka nieustanny wysiÅ‚ek, a kiedy jedno zadanie siÄ™ koÅ„czy, zaraz znajdzie siÄ™ nastÄ™pne.",
    "label": "incorrect"
}
```
```json
{
    "text": "Tutaj interesuje mnie etyczny kontekst transferu naukowej wiedzy psychologicznej z laboratorium badacza do sali wykÅ‚adowej i laboratorium studenckiego - czynniki uÅ‚atwiajÄ…ce i utrudniajÄ…ce, ale lokowane na stosunkowo wysokim poziomie ogÃ³lnoÅ›ci.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ teksty i czy sÄ… gramatycznie poprawne.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Gramatycznie poprawny: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  OkreÅ›l czy tekst jest gramatycznie poprawny czy nie. Odpowiedz {labels_str}, i nic wiÄ™cej.
  ```
- Label mapping:
    - `correct` â¡ï¸ `tak`
    - `incorrect` â¡ï¸ `nie`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-pl
```


## Reading Comprehension

### PoQuAD

PoQuAD is a Polish Question Answering dataset with contexts from Polish Wikipedia. It follows the SQuAD format with innovations including lower annotation density, abstractive answers, polar questions, and impossible questions.

This dataset was published in [this paper](https://dl.acm.org/doi/10.1145/3587259.3627548).

The original dataset consists of 51,951 samples. We use 1,024 / 256 / 2,048 samples for training, validation and testing, respectively.
We do not use the impossible questions in this version of the dataset.

Here are a few examples from the training split:

```json
{
  "context": "Luna (Karol Sevilla) jest nastolatkÄ… z Meksyku, ktÃ³ra szczÄ™Å›liwie jedzie przez Å¼ycie na wrotkach. Jak kaÅ¼da dziewczyna w jej wieku, mieszka wraz ze swojÄ… rodzinÄ…, chodzi do szkoÅ‚y i ma swojÄ… grupÄ™ znajomych. Ma rÃ³wnieÅ¼ pracÄ™ jako dostawca w restauracji typu fast food. Luna spÄ™dza wiÄ™kszoÅ›Ä‡ swojego czasu na wrotkach na nabrzeÅ¼u swego ukochanego miasta, sÅ‚uchajÄ…c piosenek skomponowanych przez jej najlepszego przyjaciela, SimÃ³na (Michael Ronda). Ale jej Å¼ycie przybiera jednak niespodziewany obrÃ³t, gdy jej rodzice otrzymujÄ… propozycjÄ™ niemoÅ¼liwÄ… do odrzucenia..., jutro rodzina Valente musi opuÅ›ciÄ‡ swÃ³j ukochany dom i przenieÅ›Ä‡ siÄ™ do innego kraju, do Argentyny. Luna musi przystosowaÄ‡ siÄ™ do nowego Å¼ycia, nowych przyjaciÃ³Å‚ i nowej szkoÅ‚y, gdzie spotyka siÄ™ Å›wiat luksusu i elit, ktÃ³ry niewiele ma z niÄ… wspÃ³lnego. Luna szuka schronienia w swojej jeÅºdzie na wrotkach, a przez nie odkrywa tor wrotkarski, Jam & Roller, ktÃ³ry oferuje jej nowy wszechÅ›wiat na koÅ‚ach. Podczas tego nowego etapu w swoim Å¼yciu Luna rozwija swojÄ… pasjÄ™ do jazdy i taÅ„ca na wrotkach oraz odkrywa drogÄ™ do nowych przyjaciÃ³Å‚ i pierwszej miÅ‚oÅ›ci, ktÃ³rÄ… znajduje w osobie zupeÅ‚nie innej od niej samej, Matteo (Ruggero Pasquarelli). Na przeszkodzie stoi jednak najpopularniejsza dziewczyna w szkole i dziewczyna Matteo, Ãmbar (Valentina Zenere), ktÃ³ra za wszelkÄ… cenÄ™ chce uczyniÄ‡ Å¼ycie Luny niemoÅ¼liwym. RÃ³wnieÅ¼ podczas rozwijania swych pasji, Luna moÅ¼e byÄ‡ o krok od odkrycia swojej prawdziwej toÅ¼samoÅ›ci.",
  "question": "Gdzie przeprowadza siÄ™ Luna?",
  "answers": {'text': array(['do Argentyny'], dtype=object), 'answer_start': array([652], dtype=int32), 'generative_answer': array(['do Argentyny'], dtype=object)}}
```
```json
{
  "context": "W sezonie 1933 Ruch zdobyÅ‚ mistrzostwo Polski. Katzy zagraÅ‚ w dziewiÄ™tnastu kolejkach ligowych. Jedynym meczem, w ktÃ³rym nie wystÄ…piÅ‚, byÅ‚o spotkanie inauguracyjne sezon przeciwko Garbarni KrakÃ³w (6:0, 2 kwietnia 1933 roku). Podczas wyjazdowego meczu towarzyskiego z PoloniÄ… Karwina (4:1, 14 maja 1933 roku) zostaÅ‚ usuniÄ™ty z boiska za krytykowanie decyzji sÄ™dziego. W paÅºdzierniku zagraÅ‚ w przegranym sparingu reprezentacji ÅšlÄ…ska, ktÃ³rej przeciwnikiem byÅ‚a reprezentacja Polski (1:2, 4 paÅºdziernika 1933 roku).",
  "question": "W ilu rundach spotkaÅ„ wziÄ…Å‚ udziaÅ‚ Stefan Katzy?",
  "answers": {'text': array(['w dziewiÄ™tnastu'], dtype=object), 'answer_start': array([60], dtype=int32), 'generative_answer': array(['W dziewiÄ™tnastu'], dtype=object)}}
```
```json
{
  "context": "NastÄ™pnego dnia Amerykanie wysÅ‚ali nad stacjÄ™ kolejowÄ… w Ploeszti 136 B-24 i 94 B-17 w asyÅ›cie 132 P-38 i 48 P-47. 1 Grupa wysÅ‚aÅ‚a na przechwycenie 23 myÅ›liwce IAR, ale tylko czÄ™Å›Ä‡ z nich odnalazÅ‚a bombowce meldujÄ…c o zestrzeleniu trzech B-24. SierÅ¼. Raghiga Dumitrescu stoczyÅ‚ walkÄ™ z czterema P-38, uszkadzajÄ…c jeden z nich, jednak pÃ³Åºniej sam zostaÅ‚ zestrzelony. Dwa inne samoloty lÄ…dowaÅ‚y na brzuchach. 5 Grupa poderwaÅ‚a 8 IAR-80 i 4 Bf 109E z 51 eskadry oraz 7 Bf 109E z 52 eskadry. Ich piloci odnotowali piÄ™Ä‡ zestrzeleÅ„ pewnych i jedno prawdopodobne. Kpt. Iliescu lÄ…dowaÅ‚ awaryjnie uszkodzonym samolotem. 6 Grupa wykonaÅ‚a 49 lotÃ³w na IAR odnotowujÄ…c piÄ™Ä‡ zwyciÄ™stw, w tym trzy potwierdzone, bez strat wÅ‚asnych. 7 Grupa wysÅ‚aÅ‚a 15 IAR-81C i 13 Bf 109G, meldujÄ…c o trzech zwyciÄ™stwach przy stracie jednego samolotu. Piloci niemieckiego III/JG 77 meldowali o 16 zestrzelonych B-24 ze stratÄ… 7 Bf 109G. O strÄ…ceniu 4 B-24 i 1 B-17 meldowali piloci z 10./JG 301. SzeÅ›Ä‡ kolejnych LiberatorÃ³w mieli zestrzeliÄ‡ piloci II/JG 51, jednego B-17 lotnicy 12./NJG 6, a jednego P-51 pilot 1./JG 302. Prawdziwe straty AmerykanÃ³w wyniosÅ‚y 10 B-24 (po piÄ™Ä‡ z 450. i 451. BG), trzy B-17 oraz jeden P-38 z 14. FG. MyÅ›liwce eskorty nie odnotowaÅ‚y ani jednego zestrzelenia.", "question": "Czy sierÅ¼antowi Raghiga Dumitrescu udaÅ‚o siÄ™ doprowadziÄ‡ do awarii ktÃ³rego z samolotÃ³w P-38?",
  "answers": {'text': array(['SierÅ¼. Raghiga Dumitrescu stoczyÅ‚ walkÄ™ z czterema P-38, uszkadzajÄ…c jeden z nich'],
      dtype=object), 'answer_start': array([244], dtype=int32), 'generative_answer': array(['tak'], dtype=object)}}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ teksty z towarzyszÄ…cymi pytaniami i
  odpowiedziami.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Pytanie: {question}
  OdpowiedÅº w maksymalnie 3 sÅ‚owach: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Odpowiedz na nastÄ™pujÄ…ce pytanie dotyczÄ…ce powyÅ¼szego tekstu w maksymalnie 3 sÅ‚owach.

  Pytanie: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset poquad
```


## Knowledge

### LLMzSzÅ

This dataset was created based on Polish national exams extracted from the archives of the Polish Central Examination Board. LLMzSzÅ (LLMs Behind the School Desk) represents the first comprehensive benchmark for the Polish language at this scale. The dataset features both academic and professional tests covering 4 types of exams from 154 different domains. The dataset was created to evaluate the ability of language models to transfer knowledge between languages and to assess their performance on Polish educational content.

The original dataset consisted of almost 19,000 closed-ended questions in a single test split. We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Czujnik do pomiaru poziomu obciÄ…Å¼enia, stosowany w wozach paszowych jako element systemu zdalnego waÅ¼enia masy mieszanki, jest czujnikiem\nChoices:\na. tensometrycznym.\nb. podczerwieni.\nc. indukcyjnym.\nd. optycznym.",
  "label": "a"
}
```
```json
{
  "text": "Wybierz prawidÅ‚owÄ… kolejnoÅ›Ä‡ wykonania operacji remontowych maszyny.\nChoices:\na. Weryfikacja, regeneracja, oczyszczenie, demontaÅ¼, badanie i odbiÃ³r maszyny po remoncie.\nb. DemontaÅ¼, weryfikacja, oczyszczenie, regeneracja, badanie i odbiÃ³r maszyny po remoncie.\nc. Oczyszczenie, demontaÅ¼, weryfikacja, regeneracja, naprawa zespoÅ‚Ã³w, montaÅ¼, badanie i odbiÃ³r maszyny po remoncie.\nd. Regeneracja, demontaÅ¼, weryfikacja, oczyszczenie, naprawa zespoÅ‚Ã³w, regeneracja, badanie i odbiÃ³r maszyny po remoncie.",
  "label": "c"
}
```
```json
{
  "text": "CieczÄ… ciÄ™Å¼kÄ… jednorodnÄ… nazywamy substancjÄ™ ciekÅ‚Ä…, ktÃ³rej gÄ™stoÅ›Ä‡ jest\nChoices:\na. rÃ³wna gÄ™stoÅ›ci wody.\nb. wiÄ™ksza od gÄ™stoÅ›ci wody.\nc. mniejsza od gÄ™stoÅ›ci wody.\nd. wypadkowÄ… gÄ™stoÅ›ci cieczy ciÄ™Å¼kiej i wody.",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ pytania wielokrotnego wyboru (z odpowiedziami).
  ```
- Base prompt template:
  ```
  Pytanie: {text}
  OdpowiedÅº: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Pytanie: {text}

  Odpowiedz na powyÅ¼sze pytanie, odpowiadajÄ…c {labels_str}, i nic wiÄ™cej.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset llmzszl
```


## Common-sense Reasoning

## Summarization

### PSC

The Polish Summaries Corpus (PSC) was published in [this paper](https://aclanthology.org/L14-1145/) and is a resource created for automated single-document summarization of Polish. The corpus contains manual summaries of news articles, with multiple independently created summaries for single texts to overcome annotator bias. It includes both abstract free-word summaries and extraction-based summaries created by selecting text spans from the original documents.

The original dataset consists only of a training split. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All splits are subsets of the original training data, with the validation and test splits sampled from the original training set.

Here are a few examples from the training split:

```json
{
  "text": "RozpoczynajÄ…cy siÄ™ 31 grudnia 2000 roku The Race ma staÄ‡ siÄ™ pokazem moÅ¼liwoÅ›ci technicznych wspÃ³Å‚czesnego jachtingu, rozwoju technologii telekomunikacyjnych, ma dowieÅ›Ä‡ siÅ‚y marketingowej wielkich wydarzeÅ„ sportowych, a takÅ¼e potÄ™gi finansowej sponsorÃ³w tego przedsiÄ™wziÄ™cia. OkoÅ‚o dziesiÄ™ciu superjachtÃ³w wystartuje 31 grudnia 2000 roku o pÃ³Å‚nocy z Barcelony. Najlepszy po okoÅ‚o dwÃ³ch miesiÄ…cach powinien wpÅ‚ynÄ…Ä‡ do Starego Portu w Marsylii.",
  "target_text": "31 grudnia 2000 roku rozpoczynajÄ… siÄ™ regaty The Race, bÄ™dÄ…ce rozwiniÄ™ciem regat dookoÅ‚a Å›wiata - Jules Verne Trophy. Jachty wystartujÄ… z Barcelony i przepÅ‚ynÄ… bez pomocy  i zawijania do portÃ³w trzy oceany.  Organizatorzy regat chcÄ… dotrzeÄ‡ do miliardÃ³w odbiorcÃ³w.  By pobiÄ‡ rekordy oglÄ…dalnoÅ›ci i zaprezentowaÄ‡ sponsorÃ³w wykorzystana zostanie najnowsza technika m.in kamery na jachtach."
}
```
```json
{
  "text": "jeÅ›li w polskich przedsiÄ™biorstwach nie zostanie przeprowadzona restrukturyzacja, z ograniczeniem zatrudnienia i wzrostem wydajnoÅ›ci, nie ma co marzyÄ‡, aby staÅ‚y siÄ™ one konkurencyjne w momencie wejÅ›cia Polski do Unii Europejskiej. wejÅ›cie zagranicznego inwestora czÄ™sto oznacza zmniejszenie zatrudnienia. Do zmniejszania liczby pracownikÃ³w prowadzÄ… fuzje przedsiÄ™biorstw. Na ochronny parasol pakietÃ³w socjalnych i odprawy dla zwalnianych mogÄ… liczyÄ‡ zatrudnieni gÃ³rnictwie i hutnictwie. Na osÅ‚onÄ™ nie mogÄ… liczyÄ‡ pracownicy przemysÅ‚u lekkiego.",
  "target_text": "W firmach konieczne sÄ… zwolnienia restrukturyzacyjne i wzrost wydajnoÅ›ci pracy. JeÅ›li porÃ³wnamy polskie przedsiÄ™biorstwa z ich zachodnimi odpowiednikami, okazuje siÄ™, Å¼e w stosunku do wielkoÅ›ci produkcji zatrudnienie u nas jest drastycznie wiÄ™ksze. GÅ‚Ä™boka restrukturyzacja jest konieczna, jeÅ›li polscy producenci chcÄ… byÄ‡ konkurencyjni po wstÄ…pieniu Polski do Unii Europejskiej. Wymusza jÄ… teÅ¼ kryzys na Wschodzie. CzÄ™sto sÄ… one rÃ³wnieÅ¼ wynikami wejÅ›cia zagranicznego inwestora lub fuzji. OprÃ³cz zwolnieÅ„ potrzebne sÄ… inwestycje."
}
```
```json
{
  "text": "Podczas II Kongresu Filmu Polskiego ogromne poruszenie Å›rodowiska filmowego wywoÅ‚aÅ‚ list ministra Andrzeja Zakrzewskiego. Minister Zakrzewski zaatakowaÅ‚ Å›rodowisko filmowe za to, Å¼e dotÄ…d nie ma nowego prawa filmowego.  Filmowcy Poczuli siÄ™ skrzywdzeni ocenami, bo straty byÅ‚y przy zmianie ustrojowej i likwidacji paÅ„stwowego mecenatu nieuniknione. A Polska najlepiej chyba ze wszystkich krajÃ³w postkomunistycznych przeprowadziÅ‚a swojÄ… kinematografiÄ™ przez ten trudny okres.",
  "target_text": "Åšrodowisko filmowe jest poruszone listem ministra kultury, ktÃ³ry krytykuje polskie kino i atakuje filmowcÃ³w m.in. za niewypracowanie nowego prawa filmowego. TwÃ³rcy czujÄ… siÄ™ skrzywdzeni bezpodstawnymi zarzutami. ZaznaczajÄ…, Å¼e to ministerstwo odpowiada za zatrzymanie prac nad ustawÄ… o kinematografii. Publiczna krytyka i niedbaÅ‚oÅ›Ä‡ o interesy Å›rodowiska twÃ³rczego sÄ… oburzajÄ…ce. Minister potwierdza, Å¼e jest autorem listu, i nie akceptuje obecnej formuÅ‚y Komitetu Kinematografii."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  PoniÅ¼ej znajdujÄ… siÄ™ artykuÅ‚y z towarzyszÄ…cymi streszczeniami.
  ```
- Base prompt template:
  ```
  ArtykuÅ‚: {text}
  Streszczenie: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  ArtykuÅ‚: {text}

  Napisz streszczenie powyÅ¼szego artykuÅ‚u.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset psc
```
