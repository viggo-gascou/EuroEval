# üá©üá∞ Danish

This is an overview of all the datasets used in the Danish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Angry Tweeets

This dataset was published in [this
paper](https://aclanthology.org/2021.nodalida-main.53/) and was a crowd-sourcing effort
to annotate sentiment of Danish tweets.

The original full dataset consists of 3,458 samples, and we are using a split of 1,024 /
256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples
used in total). All the samples in the original test set are included in our test set,
but our test set is furthermore using a subset of the original training set as test
samples as well. The original dataset did not have a validation split, so we have
created one by sampling from the training set.

Here are a few examples from the training split:

```json
{
  "text": "Jeg tror, det der var kampen. Goff virker lost",
  "label": "negative"
}
```
```json
{
  "text": "@USER @USER Vi bruger ogs√• snildt 1-2 timer (nogle gange flere timer end det) p√• at putte den yngste. Det er oftest Tommi, som g√∏r det, for jeg g√•r helt amok i processen. S√• sm√∏rer jeg madpakker og rydder op i stedet.",
  "label": "neutral"
}
```
```json
{
  "text": "Er du nysgerrig p√•, hvordan du diskvalificerer dig selv fra at blive taget seri√∏st i den offentlige debat? Naser har svaret. #dkpol #dkmedier [LINK]",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∏lgende er tweets og deres sentiment, som kan v√¶re 'positiv', 'neutral' eller 'negativ'.
  ```
- Base prompt template:
  ```
  Tweet: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tweet: {text}

  Klassificer sentimentet i tweetet. Svar kun med 'positiv', 'neutral' eller 'negativ'.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiv`
    - `neutral` ‚û°Ô∏è `neutral`
    - `negative` ‚û°Ô∏è `negativ`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset angry-tweeets
```


## Named Entity Recognition

### DANSK

This dataset was published in [this
paper](https://doi.org/10.3384/nejlt.2000-1533.2024.5249) and is a manually annotated
subset of [Danish Gigaword](https://aclanthology.org/2021.nodalida-main.46/) with the 18
different named entities, following the OntoNotes 5.0 scheme. It was annotated by 10
different annotators.

The original full dataset consists of 15,062 samples, and we are using a split of 1,024
/ 256 / 1,024 samples for training, validation and testing, respectively (so 2,304
samples used in total). All samples in the validation and test sets of our version also
belong to the original validation and test set, respectively.

We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003
labelling scheme, which is more common in the NER literature. The mapping is as follows:

- `PERSON` ‚û°Ô∏è `PER`
- `LOCATION` ‚û°Ô∏è `LOC`
- `FACILITY` ‚û°Ô∏è `LOC`
- `GPE` ‚û°Ô∏è `LOC`
- `ORGANIZATION` ‚û°Ô∏è `PER`
- `EVENT` ‚û°Ô∏è `MISC`
- `LANGUAGE` ‚û°Ô∏è `MISC`
- `PRODUCT` ‚û°Ô∏è `MISC`
- `WORK OF ART` ‚û°Ô∏è `MISC`
- `NORP` ‚û°Ô∏è `MISC`
- `CARDINAL` ‚û°Ô∏è `O`
- `DATE` ‚û°Ô∏è `O`
- `LAW` ‚û°Ô∏è `O`
- `MONEY` ‚û°Ô∏è `O`
- `ORDINAL` ‚û°Ô∏è `O`
- `PERCENT` ‚û°Ô∏è `O`
- `QUANTITY` ‚û°Ô∏è `O`
- `TIME` ‚û°Ô∏è `O`

Here are a few examples from the training split:

```json
{
  "tokens": array(['I', 'dette', 'efter√•r', 'har', 'Gr√∏nland', 'taget', 'en', 'stor', 'beslutning', 'ved', 'folkeafstemningen', 'den', '25.', 'november', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['√Öh', ',', 'Petra', ',', 'vis', 'mig', 'din', 'krop', '.'], dtype=object),
  "labels": array(['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Fravalget', 'af', 'revision', 'registreres', 'automatisk', 'ved', 'anmeldelse', 'af', 'stiftelse', 'af', 'selskabet', 'hos', 'Erhvervs-styrelsen', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  F√∏lgende er s√¶tninger og JSON-ordb√∏ger med de navngivne enheder, som forekommer i den givne s√¶tning.
  ```
- Base prompt template:
  ```
  S√¶tning: {text}
  Navngivne enheder: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S√¶tning: {text}

  Identific√©r de navngivne enheder i s√¶tningen. Du skal outputte dette som en JSON-ordbog med n√∏glerne 'person', 'sted', 'organisation' og 'diverse'. V√¶rdierne skal v√¶re lister over de navngivne enheder af den type, pr√¶cis som de forekommer i s√¶tningen.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `person`
    - `I-PER` ‚û°Ô∏è `person`
    - `B-LOC` ‚û°Ô∏è `sted`
    - `I-LOC` ‚û°Ô∏è `sted`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `diverse`
    - `I-MISC` ‚û°Ô∏è `diverse`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset dansk
```


### Unofficial: DaNE

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.565/)
and is a manually NER annotated version of the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master). The NER
labels follow the CoNLL-2003 labelling scheme.

The original full dataset consists of 4,383 / 564 / 565 samples for training, validation
and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation
and testing, respectively (so 3,328 samples used in total). These splits are new and
there can thus be some overlap between the original validation and test sets and our
validation and test sets.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Det', 'var', 'det', '√•r', ',', 'hans', 'f√∏rste', 'LP', ',', '"', 'With', 'A', 'Little', 'Help', 'From', 'My', 'Friends', '"', ',', 'udkom', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Eddie', 'Carbone', ',', 'italiensk-amerikansk', 'havnearbejder', 'i', 'New', 'York', '.'], dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'I-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['"', 'Jeg', 'er', 'mig', '!', '"', 'insisterer', 'han', 'under', 'det', 'flere', 'hundrede', '√•r', 'gamle', 'egetr√¶', ',', 'liggende', ',', 'som', 'den', 'popflab', 'han', 'er', ',', 'p√•', 'ryggen', 'i', 'sine', 'orange', 'jeans', ',', 't-shirt', '-', 'som', 'naturligvis', 'stiller', 'et', 'solbrunt', 'beh√•ret', 'bryst', 'til', 'skue', '-', 'et', 'par', '68er', '"', 'make', 'love', 'not', 'war', '"', 'solbriller', 'han', 'netop', 'har', 'k√∏bt', 'i', 'Paris', ',', 'og', 'en', 'Kings', 'i', 'k√¶ften', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O'], dtype=object)
}
```


## Linguistic Acceptability

### ScaLA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original dataset consists of 5,512 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Samme dame dukkede netop nu op sammen med Odd-Catla's erkl√¶rede yndling, v√¶bneren Aikin af Cantir.",
  "label": "correct"
}
```
```json
{
  "text": "Gebyrets st√∏rrelse afh√¶nger nemlig af helt, i hvilken kategori den p√•g√¶ldende \"levnedsmiddelvirksomhed\" placeres.",
  "label": "incorrect"
}
```
```json
{
  "text": "Den statsansatte dyrl√¶ge Kronf√•gels p√• slagteri i Kristiansstad, Karl Erik Bj√∏rkman, understreger, bel√¶gningen hos producenten betyder meget for dyrenes trivsel:",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∏lgende er s√¶tninger og om de er grammatisk korrekte.
  ```
- Base prompt template:
  ```
  S√¶tning: {text}
  Grammatisk korrekt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S√¶tning: {text}

  Bestem om s√¶tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s√¶tningen er korrekt, og 'nej', hvis den ikke er.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `ja`
    - `incorrect` ‚û°Ô∏è `nej`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-da
```


## Reading Comprehension

### ScandiQA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the Danish part of the [MKQA
dataset](https://aclanthology.org/2021.tacl-1.82/). The MKQA dataset is based on the
English [Natural Questions dataset](https://aclanthology.org/Q19-1026/), based on search
queries from the Google search engine. The questions and answers were manually
translated to Danish (and other languages) as part of MKQA, and the contexts were in
ScandiQA-da machine translated using the [DeepL translation
API](https://www.deepl.com/en/pro-api/). A rule-based approach was used to ensure that
the translated contexts still contained the answer to the question, potentially by
changing the answers slightly.

The original full dataset consists of 6,810 / 500 / 500 samples for training,
validation and testing, respectively (so 3,328 samples used in total).
We use a 1,024 / 256 / 2,048 split for training, validation and testing, respectively,
where the splits are made by randomly sampling from the full dataset without considering
the original train/validation/test splits.

Here are a few examples from the training split:

```json
{
  "context": "\"(Sittin\' On) The Dock of the Bay\" er en sang, der er skrevet af soul-sangeren Otis Redding og guitaristen Steve Cropper sammen. Den blev indspillet af Redding to gange i 1967, herunder en gang f√• dage f√∏r hans d√∏d i et flystyrt. Sangen blev udgivet p√• Stax Records\' Volt-label i 1968 og blev den f√∏rste posthume single, der l√• √∏verst p√• hitlisterne i USA. Den n√•ede op som nummer 3 p√• den britiske single-liste.",
  "question": "Hvem sang sitting on the dock of the bay?",
  "answers": {
    "answer_start": array([79]),
    "text": array(["Otis Redding"], dtype=object)
  }
}
```
```json
{
  "context": "The Cat in the Hat Knows a Lot About That!\nKatten i hatten ved meget om det!\n\n\n\nKatten i hatten pilot\n\n\n\nGenre\nB√∏rne-tv/undervisning/komedie\n\n\nInstrueret af\nTony Collingwood\n\n\nStemmer fra\nMartin Short\nJacob Ewaniuk\nAlexa Torrington\nRob Tinkler\n\n\nKomponist af temamusik\nDavid Schweitzer\n\n\nKomponist(er)\nDavid Schweitzer\n\n\nOprindelsesland\nCanada\nDet Forenede Kongerige\nUSA\n\n\nOprindelige sprog\nEngelsk\n\n\nAntal s√¶soner\n2\n\n\nAntal episoder\n60 (liste over episoder)\n\n\nProduktion\n\n\nL√∏betid\n30 minutter\n\n\nProduktionsselskab(er)\nCollingwood O'Hare Productions\nPortfolio Entertainment\nRandom House Children's Entertainment\nTreehouse TV\n\n\nDistribut√∏r\nTreehouse TV\n\n\nUdgivelse\n\n\nOprindelige netv√¶rk\nTreehouse TV (Canada)\nPBS Kids (USA)\nCITV og Tiny Pop (UK)\n\n\nBilledformat\n480i (SDTV)\n1080i (HDTV)\n\n\nOriginaludgivelse\n7. august 2010 (2010-08-07) - nu\n\n\nEksterne links\n\n\nWebsted\npbskids.org/catinthehat/",
  "question": "Hvem synger titelmelodien til the cat in the hat?",
  "answers": {
    "answer_start": array([269]),
    "text": array(["David Schweitzer"], dtype=object)
  }
}
```
```json
{
  "context": "Modern Slavery Act 2015\nLoven om moderne slaveri fra 2015 er en lov fra Det Forenede Kongeriges parlament. Den har til form√•l at bek√¶mpe slaveri i Det Forenede Kongerige og konsoliderer tidligere lovovertr√¶delser vedr√∏rende menneskehandel og slaveri. Loven g√¶lder for England og Wales. Lovforslaget blev forelagt underhuset i udkast i oktober 2013 af James Brokenshire, parlamentarisk undersekret√¶r for kriminalitet og sikkerhed, i oktober 2013. Lovforslagets sponsorer i indenrigsministeriet var Theresa May og Lord Bates. Det fik kongelig samstemmende udtalelse og blev lov den 26. marts 2015.",
  "question": "Hvorn√•r tr√•dte den moderne slaveri i kraft?",
  "answers": {
    "answer_start": array([580]),
    "text": array(["26. marts 2015"], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  F√∏lgende er tekster med tilh√∏rende sp√∏rgsm√•l og svar.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Sp√∏rgsm√•l: {question}
  Svar med maks. 3 ord: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Besvar f√∏lgende sp√∏rgsm√•l om teksten ovenfor med maks. 3 ord.

  Sp√∏rgsm√•l: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scandiqa-da
```


### Unofficial: BeleBele-da

This dataset was published in [this paper](https://aclanthology.org/2024.acl-long.44/) and features multiple-choice reading comprehension questions across 122 languages.

The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Tekst: Prognoserne siger, at stormen, der er omkring 645 mil (1040 km) vest for Kap Verde-√∏erne, sandsynligvis vil forsvinde, f√∏r den truer nogen landomr√•der. Fred har i √∏jeblikket vinde p√• 165 km/t og bev√¶ger sig mod nordvest. Fred er den heftigste tropiske cyklon, der nogensinde er blevet registreret s√• sydligt og √∏stligt i Atlanterhavet, siden man begyndte at bruge satellitbilleder, og kun den tredje store orkan, der er registreret √∏st for 35¬∞V.\nSp√∏rgsm√•l: Da Fred befandt sig n√¶r Kap Verde-√∏erne, hvilken retning bev√¶gede den sig s√• mod?\nSvarmuligheder:\na. Vest\nb. Syd\nc. √òst\nd. Nordvest",
  "label": "d"
}
```
```json
{
  "text": "Tekst: "Siden Pakistan i 1947 blev uafh√¶ngigt af det britiske styre, har den pakistanske pr√¶sident udpeget ""politiske agenter"", som styrer FATA, og som har n√¶sten fuldst√¶ndig kontrol over omr√•derne. Disse agenter er ansvarlige for at levere regerings- og retstjenester i henhold til artikel 247 i den pakistanske forfatning."\nSp√∏rgsm√•l: Hvem leverer retslige tjenester til FATA?\nSvarmuligheder:\na. Den pakistanske regering\nb. Politiske agenter\nc. Pakistans pr√¶sident\nd. Den britiske regering",
  "label": "b"
}
```
```json
{
  "text": "Tekst: Alle er en del af samfundet og benytter transportsystemerne. N√¶sten alle klager over transportsystemerne. I udviklede lande h√∏rer du sj√¶ldent liges√• mange klager over vandkvalitet eller broer, der styrter sammen. Hvorfor giver transportsystemerne anledning til s√•danne klager, hvorfor svigter de p√• daglig basis? Er transportingeni√∏rer blot inkompetente? Eller foreg√•r der noget mere fundamentalt?\nSp√∏rgsm√•l: Hvilken offentlig service siges at skabe st√∏rst utilfredshed i udviklede lande?\nSvarmuligheder:\na. Vandkvalitet\nb. Brobyggelse\nc. Offentlig transport\nd. Uddannelse",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset belebele-da
```

### Unofficial: MultiWikiQA-da

This dataset will be published in an upcoming paper, and contains Danish Wikipedia
articles with generated questions and answers, using the LLM Gemini-1.5-pro.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": 'R√∏dsp√¶tten (Pleuronectes platessa) er en fladfisk, der findes overalt i de danske farvande. Den er i √∏vrigt udbredt fra Middelhavet til Island og Hvidehavet. Den foretr√¶kker steder, hvor bunden best√•r af sten, sand og grus. De unge r√∏dsp√¶tter findes p√• lavt vand, mens de voksne foretr√¶kker 10-50 meters dybde. R√∏dsp√¶tten er en h√∏jrevendt fladfisk, idet det normalt er h√∏jre side, der under larvens forvandling bliver til overside.\n\nUdseende \nR√∏dsp√¶tten kan blive op til 100 centimeter, men bliver i Danmark sj√¶ldent over 50 centimeter. Den kendes bedst p√•, at der bag √∏jnene l√∏ber en buet k√∏l med 4-7 benknuder. Sk√¶llene er sm√• og glatte og ikke taglagte. Munden er lille med ret tykke l√¶ber. Begge √∏jne findes normalt p√• fiskens h√∏jre side. P√• oversiden er r√∏dsp√¶tten oftest brunlig med et gr√∏nligt sk√¶r og med spredte r√∏dlige pletter, der ofte er omgivet af lyse eller m√∏rke ringe. Undersiden er hvid.\n\nLevevis \nR√∏dsp√¶tten lever is√¶r af b√∏rsteorme og tyndskallede muslinger. Den er mest aktiv i d√∏gnets m√∏rke timer, mens den skjuler sig p√• bunden om dagen. Den skifter farve efter bundens farve og struktur. R√∏dsp√¶ttens naturlige fjender er ud over mennesket f.eks. krabber og torsk.\n\nForplantning \nHannerne bliver i Nords√∏en k√∏nsmodne 3-4 √•r gamle og en l√¶ngde p√• 20 centimeter, mens hunnerne k√∏nsmodner et par √•r senere. I √òsters√∏en bliver begge k√∏n tidligere k√∏nsmodne. Gydningen foreg√•r normalt i 20-50 meters dybde i perioden januar til juni. R√∏dsp√¶tten foretr√¶kker en temperatur p√• 6\xa0¬∞C til gydningen. √Üggene er glasklare med en diameter p√• cirka 2 millimeter og flyder op til overfladen. Efter 2-3 uger kl√¶kkes de 6 millimeter store larver. Larverne lever af planktonorganismer og begynder efter cirka 5 uger med en l√¶ngde p√• 1 centimeter en forvandling, hvor venstre √∏je vandrer op over hovedet, der vrides, og kroppen bliver bredere. Til at begynde med sv√∏mmer de sm√• r√∏dsp√¶tter skr√•t og siden med h√∏jre side opad. Med en l√¶ngde p√• 1,2-1,4 centimeter skifter de fra et pelagisk liv til at leve p√• lavt vand langs kysterne. I det f√∏rste efter√•r m√•ler r√∏dsp√¶tten 7-12 centimeter og tr√¶kker ud, for at overvintre p√• dybere vand.\n\nKilder/Henvisninger \n\n C. V. Otterstr√∏m (1881-1962).\xa0Danmarks Fauna. Fisk II. Bl√∏dfinnefisk. G.E.C. Gads Forlag. K√∏benhavn 1914.\n\nFladfisk',
    "question": 'Hvilken side af r√∏dsp√¶tten vender typisk opad?',
    "answers": {
        "answer_start": array([369]),
        "text": array(['h√∏jre side'], dtype=object)
    }
}
```
```json
{
    "context": 'Mzilikazi ("blodvejen" eller "den store vej" ca. 1790‚Äì9. september 1868) var en sydafrikansk konge som grundlagde matabelekonged√∏mmet i det omr√•de, som nu er Zimbabwe. Han var s√∏n af Matshobana og blev f√∏dt n√¶r Mkuze i Zululand (nu del af Sydafrika) og d√∏de ved Ingama i Matabeleland (n√¶r Bulawayo, Zimbabwe). Mange regner ham som den st√∏rste sydafrikanske milit√¶rleder efter zulukongen Shaka.\n\nHan f√∏rte sin stamme, khumalo, p√• en 800 km lang rejse fra Zululand til det, som nu er Zimbabwe. P√• vejen viste han betydelige statsmandsevner, da han samlede sit eget folk og de mange stammer han erobrede, til et stort,  etnisk rigt og centraliseret konged√∏mme.\n\nHan var oprindelig en af Shakas l√∏jtnanter, men i 1823 gjorde han opr√∏r. Frem for at m√∏de rituel henrettelse, flygtede han sammen med sin stamme. Han rejste f√∏rst til Mozambique og i 1826 ind i Transvaal p√• grund af fortsatte angreb fra sine fjender.\n\nFortsatte angreb fik ham f√∏rst til at flytte til dagens Botswana og i 1837 til det, som nu er Zambia Han klarede ikke at erobre den indf√∏dte kololo‚Äìnation der og rejste til det, som blev kendt som Matabeleland (i dagens Zimbabwe) og slog sig ned der i 1840.\n\nEfter hans ankomst organiserede han sine tilh√¶ngere i et milit√¶rsystem med regiment‚Äìkraaler som kong Shakas, som blev st√¶rke nok til at afvise boernes angreb i 1847‚Äì1851 og tvinge den Sydfrikanske Republiks regering til at underskrive en fredsaftale med ham i 1852.\n\nMzilikazi var generelt venlig over for europ√¶isk rejsende, f√∏rte opdagelsen af guld i Matabeleland i 1867 til en flom af bos√¶ttere, som han ikke kunne kontrollere, og som f√∏rte til konged√∏mmets endelige nederlag under hans efterf√∏lger Lobengula.\n\nKongelige fra historiske riger',
    "question": 'Med hvilket √∏genavn var Mzilikazi kendt?',
    "answers": {
        "answer_start": array([11]),
        "text": array(['"blodvejen" eller "den store vej"'], dtype=object)
    }
}
```
```json
{
    "context": 'Jean-Nicolas Bouilly (24. januar 1763 i La Coudraye ved Tours ‚Äì 14. april 1842 i Paris) var en fransk forfatter. \n\nEfter at have studeret jura sluttede Bouilly sig ved revolutionens udbrud til Mirabeau og Barnave og bekl√¶dte forskellige embeder, i hvilke han navnlig virkede for indf√∏relsen af prim√¶rskoler og for folkeoplysning i det hele taget. Senere trak han sig tilbage og vedblev at leve uafh√¶ngig til sin d√∏d. 1790 opf√∏rtes hans op√©ra comique Pierre le Grand, med musik af Gr√©try. Af hans senere dramatiske arbejder kan n√¶vnes L\'abb√© de l\'√âp√©e(1795), Les deux journ√©es (1800), komponeret af Cherubini, Fanchon (1802), komponeret af Himmel, L\'intrigue aux fen√™tres, Une folie (1803, med musik af M√©hul; p√• dansk ved N.T. Bruun: "Ungdom og Galskab" [1806], med musik af Du Puy), Mme. de S√©vign√© (1805) og s√• videre. Desuden oversatte han flere stykker af Kotzebue. Hans skrifter for ungdommen stod i sin tid i h√∏j kurs; hans stil er vidtsv√¶vende og retorisk, hans billeder skruede, hele tonen s√• sentimental, at han fik navnet le po√®te lacrymal. Af disse skrifter kan n√¶vnes: Contes offerts aux enfants de France, Contes √† ma fille (1809), Conseils √† ma fille (1811) og Les jeunes femmes (1819).\n\nKilder \n\n \n\nDramatikere fra Frankrig\nFranskm√¶nd i 1700-tallet\nFranskm√¶nd i 1800-tallet\nSalmonsens',
    "question": 'Med hvilke politiske personer allierede Bouilly sig ved revolutionens begyndelse?',
    "answers": {
        "answer_start": array([193]),
        "text": array(['Mirabeau og Barnave'], dtype=object)
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  F√∏lgende er tekster med tilh√∏rende sp√∏rgsm√•l og svar.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Sp√∏rgsm√•l: {question}
  Svar med maks. 3 ord: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Besvar f√∏lgende sp√∏rgsm√•l om teksten ovenfor med maks. 3 ord.

  Sp√∏rgsm√•l: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset multi-wiki-qa-da
```


## Knowledge

### Danske Talem√•der

This dataset was created by The Danish Language and Literature Society, published
[here](https://sprogteknologi.dk/dataset/1000-talemader-evalueringsdatasaet). The
dataset features Danish idioms along with their official meaning. For each idiom, three
negative samples were created: (a) a random idiom, (b) a concrete made-up idiom, and (c)
an abstract made-up idiom. The dataset was created to evaluate the ability of language
models to understand Danish idioms.

The original full dataset consists of 1,000 samples. We use a 128 / 64 / 808 split for
training, validation and testing, respectively (so 1,000 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Hvad betyder udtrykket 'tale nogen efter munden'?\nSvarmuligheder:\na. v√¶re f√∏jelig og give nogen ret selvom man ikke n√∏dvendigvis er enig\nb. erkl√¶re sig helt enig med en anden person\nc. sige det pr√¶cis samme som en anden; efterabe\nd. v√¶re egoistisk og sn√¶versynet; kun t√¶nke p√• sig selv",
  "label": "a"
}
```
```json
{
  "text": "Hvad betyder udtrykket 'der falder en sten fra √©ns hjerte'?\nSvarmuligheder:\na. en bestemt (kriminel, efters√∏gt) person er forsvundet\nb. man bliver fri for en sorg eller bekymring; man bliver lettet\nc. man mister √©n man har k√¶r\nd. en sten forlader et hjerte man er i besiddelse af",
  "label": "b"
}
```
```json
{
  "text": "Hvad betyder udtrykket 'have spidse albuer'?\nSvarmuligheder:\na. person der har det meget d√•rligt fysisk og psykisk\nb. have ophobet vrede over l√¶ngere tid\nc. h√¶vde sig p√• andres bekostning\nd. have knogler der tr√¶der tydeligt frem p√• ens albuer",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Hvad er betydningen af f√∏lgende talem√•de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Hvad er betydningen af f√∏lgende talem√•de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset danske-talemaader
```


### Danish Citizen Tests

This dataset was created by scraping the Danish citizenship tests (indf√∏dsretspr√∏ven)
and permanent residency tests (medborgerskabspr√∏ven) from 2016 to 2024. These are
available on the [official website of the Danish Ministry of International Recruitment
and Integration](https://danskogproever.dk/).

The original full dataset consists of 870 samples. We use an 345 / 90 / 525 split for
training, validation and testing, respectively. Here all the citizenship tests belong to
the test split, as well as the newest permanent residency tests. The validation split
contains the newer permanent residency tests after the ones in the test split, and the
training split contains the oldest permanent residency tests.

Here are a few examples from the training split:

```json
{
  "text": "Hvilket parti tilh√∏rte Lars L√∏kke Rasmussen, da han var statsminister i perioderne 2009-11 og 2015-19?\nSvarmuligheder:\na. Venstre\nb. Socialdemokratiet\nc. Det Konservative Folkeparti",
  "label": "a"
}
```
```json
{
  "text": "Hvilket af f√∏lgende omr√•der har kommunerne ansvaret for driften af?\nSvarmuligheder:\na. Domstole\nb. Vuggestuer\nc. Sygehuse",
  "label": "b"
}
```
```json
{
  "text": "Hvilken organisation blev Danmark medlem af i 1945?\nSvarmuligheder:\na. Verdenshandelsorganisationen (WTO)\nb. Den Europ√¶iske Union (EU)\nc. De Forenede Nationer (FN)",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset danish-citizen-tests
```


### Unofficial: MMLU-da

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Danish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "Hvilket af f√∏lgende coronavirusser har for√•rsaget tusindvis af d√∏dsfald over hele verden som en 'opst√•et' virus?\nSvarmuligheder:\na. MERS\nb. SARS\nc. OC43\nd. HKU1",
  "label": "a"
}
```
```json
{
  "text": "Hvilken orbitale v√¶g er mest sandsynligt at kollapse i en 'blow out' fraktur?\nSvarmuligheder:\na. Taget\nb. Gulvet\nc. Den laterale v√¶g\nd. Den mediale v√¶g",
  "label": "b"
}
```
```json
{
  "text": "Hvad er navnet p√• den st√∏rste struktur i Teotihuac√°n, og hvor mange platforme og pyramider blev bygget der?\nSvarmuligheder:\na. M√•nepyramiden; 250\nb. Templet for den fjerkr√¶kl√¶dte slange; 400\nc. Solpyramiden; 600\nd. Inskriptionstemplen; 700",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


### Unofficial: ARC-da

This dataset is a machine translated version of the English [ARC
dataset](https://doi.org/10.48550/arXiv.1803.05457) and features US grade-school science
questions. The translation to Danish was done by the University of Oregon as part of
[this paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 1,110 / 297 / 1,170 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,
validation and testing, respectively (so 2,304 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Et farmaceutisk firma har offentliggjort resultaterne af et begr√¶nset eksperiment, der unders√∏ger den beskyttende virkning af en kemisk forbindelse mod h√∏je doser af UV-str√•ler p√• hudceller. Senere blev det opdaget, at resultaterne ikke var reproducerbare. Hvilken handling kunne forskere fra firmaet have foretaget for at undg√• at offentligg√∏re fejlagtige resultater?\nSvarmuligheder:\na. Udf√∏r flere fors√∏g.\nb. Brug kun lave niveauer af str√•ling.\nc. Brug forskellige b√∏lgel√¶ngder af str√•ling.\nd. Unders√∏g resultaterne af lignende eksperimenter, f√∏r man dannede en hypotese.",
  "label": "a"
}
```
```json
{
  "text": "En ingeni√∏r skal beregne den potentielle energi af en rutschebanekabine √∏verst p√• en skr√•ning. Hvilken information ville bedst hj√¶lpe ingeni√∏ren med at bestemme den potentielle energi af kabine?\nSvarmuligheder:\na. den afstand, som rutschebanekabinen skal rejse\nb. massen af rutschebanekabinen ved fuld kapacitet\nc. den gennemsnitlige v√¶gt af en tom rutschebanekabine\nd. retningen, som rutschebanekabinen bev√¶ger sig i",
  "label": "b"
}
```
```json
{
  "text": "En studerende h√¶ldte vand i en plastbakke. Studerende satte derefter bakken i fryseren. Hvilken egenskab ved vand √¶ndrede sig, da vandet fryser?\nSvarmuligheder:\na. Vandet blev til en gas.\nb. Massen af vandet steg.\nc. Vandet tog en bestemt form.\nd. Smagen af vandet √¶ndrede sig ikke.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


## Common-sense Reasoning

### HellaSwag-da

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Disse mennesker tr√¶der pedalerne med kun det ene ben og st√•r midt p√• cyklen med det andet ben, der holder deres h√¶nder oppe. n√¶ste g√∏r de\nSvarmuligheder:\na. en anden √∏velse, hvor de s√¶tter det ene ben p√• pedalen, mens de har det andet ben ude og hopper op og ned.\nb. tager hinandens h√¶nder og udf√∏rer en eller anden dansebev√¶gelse p√• b√∏rsterne, som de bruger til at snurre rundt med deres kroppe og hoppe med h√¶nderne oppe.\nc. drejer med deres forstenede h√¶nder, laver en U-vending og starter derefter deres handlinger igen og igen.\nd. skifter til at st√• ved hj√¶lp af to arme for at balancere sig selv.",
  "label": "a"
}
```
```json
{
  "text": "[header] S√•dan dr√¶ber du frugtfluer [title] Brug r√•dden frugt. [step] Dit problem med frugtfluer begyndte sandsynligvis f√∏rst, da du opdagede, at du havde efterladt nogle frugter, der til sidst blev r√•dne. Brug den metode, der samlede fluene f√∏rste gang til at fange dem igen, men denne gang f√∏r dem til en mere morbide slutning.\nSvarmuligheder:\na. Dr√¶b fluene ved at tr√¶kke dem fra deres rede eller ved at bruge tunge k√¶der med t√¶nger til at fange dem og placere dem i en spand eller stuen. Du kan ogs√• bruge dyreaff√∏ring s√•som fiske- og ande-urin.\nb. Placer et stykke r√•dden frugt i en sk√•l og str√¶k klart plastik over toppen. Sk√¶r flere sm√• huller i plastikken med en tandstik og lad det st√• t√¶t p√• stedet med fluene.\nc. Efter at have fors√∏gt at fange dobbelt s√• mange fluer, som du kan, skal du fjerne de ubehagelige frugtstykker fra pakken og bage dem i 2-3 minutter. Fluene vil flyde √∏verst p√• den s√∏de marmelade, n√•r du fjerner frugten fra marmeladen.\nd. [substeps] Tjek d√•ser for knotten, melbiller og fluer. K√∏b blomster fra havecentret, hvis du ikke har al produktion i n√¶rheden.",
  "label": "b"
}
```
```json
{
  "text": "En mand st√•r indend√∏rs p√• en platform foran tre tilskuere og l√∏fter en tung v√¶gtstang. En mand n√¶rmer sig en v√¶gtstang p√• gulvet og st√•r foran den og forbereder sig p√• at l√∏fte den. manden\nSvarmuligheder:\na. l√∏fter v√¶gtstangen, der h√¶nger i luften p√• platformen, og vender sig mod tilskuerne.\nb. l√∏fter v√¶gtstangen og viser, hvordan han udf√∏rer det, idet han pauser p√• hver stang for at m√•le v√¶gten.\nc. b√∏jer sig derefter i kn√¶ene og l√¶gger h√¶nderne p√• v√¶gtens stangdel.\nd. l√∏fter derefter klokken p√• sine skuldre, l√¶ner sig tilbage, s√¶tter armene bag hovedet og l√∏fter den let.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset hellaswag-da
```


### Unofficial: GoldenSwag-da

This dataset is a filtered and machine translated version of the English [HellaSwag dataset](https://aclanthology.org/P19-1472/), featuring both video descriptions from ActivityNet as well as how-to articles from WikiHow. The machine translated version was published in [this paper](https://doi.org/10.48550/arXiv.2410.08928) and was done using DeepL, and the filtering was published in [this paper](https://doi.org/10.48550/arXiv.2504.07825), which resulted in higher quality samples.

The original full dataset consists of 1530 / 1530 samples for training and validation, respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048 samples for training, validation, and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "S√•dan giver du dig selv en fransk manicure ved hj√¶lp af tape. Gnid en vatpind med neglelakfjerner p√• alle dine negle. Det vil ikke kun fjerne afskallet lak eller rester af lak, men det vil ogs√• fjerne fugtighedscreme fra neglen. Hvis du har et fugtighedsbevarende middel, s√•som lotion eller olie, p√• neglen, vil lakken ikke sidde ordentligt fast.\nSvarmuligheder:\na. Kom lakfjerneren i en lille sk√•l. Du skal bruge den om et par minutter til at f√• denne opl√∏sning p√• t√¶erne.\nb. Fordel et fugtgivende pulver over alle dine negle med cirkul√¶re bev√¶gelser, indtil du kommer i kontakt med huden. Pol√©r altid neglene, inden du g√•r i gang.\nc. Skum vattet i lakfjerneren. Brug en bl√∏d vaskeklud til at samle lakken op.\nd. S√∏rg for, at du har skabt et perfekt l√¶rred til din franske manicure. P√•f√∏r din basisfarve p√• hele neglen.",
  "label": "d"
}
```

```json
{
  "text": "S√•dan forbedrer du et lille barns tale. Kom ned p√• deres niveau. S√¶t dig p√• hug eller p√• gulvet. Det vil f√• deres opm√¶rksomhed.\nSvarmuligheder:\na. Du vil tale med dit barn i stedet for til det. Hun vil ogs√• kunne se din mund og f√• visuelle tegn p√•, hvordan man siger bestemte lyde.\nb. L√∏ft om n√∏dvendigt h√¶nderne sammen til knytn√¶ver. Hvis du str√¶kker dine h√¶nder til knytn√¶ver og g√∏r det, mens du taler, vil dit barn sandsynligvis g√∏re det samme.\nc. Pr√∏v at v√¶re s√• stille som muligt, og tal kun til dem, n√•r de er rolige. Hvis du taler l√¶nge nok, vil de til sidst h√∏re din stemme.\nd. Lad dem bede dig om at rykke t√¶ttere p√• dem. Hvis det er muligt, s√• brug en siddepind i hovedh√∏jde.",
  "label": "a"
}
```

```json
{
  "text": "S√•dan bruger du en bodysuit. V√¶lg en bodysuit, der smigrer dine yndlingstr√¶k. Med s√• mange muligheder og stilarter kan bodysuiten virkelig v√¶re universelt flatterende. For at finde en body, der ser godt ud p√• dig, skal du overveje, hvilken del af din krop du vil fremh√¶ve.\nSvarmuligheder:\na. Det kan v√¶re underarmene, benene eller andre steder, der stikker ud. M√•ske har du for eksempel en flot l√¶bespalte, som du gerne vil fremh√¶ve.\nb. Find ud af, hvilken del af din krop du vil fremh√¶ve, og sk√¶r s√• ned p√• det, der fremh√¶ver denne del. Hvis du for eksempel √∏nsker, at overdelene skal fremh√¶ve dine bryster mest muligt, kan bikinitrusserne ogs√• b√¶res omkring det omr√•de.\nc. Hvis du for eksempel er stolt af dine tonede arme, skal du v√¶lge en body uden √¶rmer eller med halterneck. Start med en bodysuit i t-shirt-stil, hvis du er ved at varme op til trenden.\nd. Beslut dig for, hvor mange forskellige dele af dig, din body skal fremh√¶ve. Hvis du for eksempel vil have et sporty look, skal din body ogs√• fremh√¶ve en del af din krop i stedet for en s√¶rlig i√∏jnefaldende del.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset goldenswag-da
```


## Summarization

### Nordjylland News

This dataset is based on news articles from the Danish news site [TV2
Nord](https://www.tv2nord.dk/), where the summaries are taken as the introductory
paragraphs of the articles.

The original full dataset consists of 75,200 samples. We use an 1,024 / 256 / 2,048
split for training, validation and testing, respectively (so 3,328 samples used in
total).

Here are a few examples from the training split:

```json
{
  "text": "Jacob Emil Andersen viste s√∏ndag rundt p√• Halvorsminde Efterskole ved Hj√∏rring. Skolen har ligget p√• samme sted siden 1903. Han er selv elev, da en IT-linje p√• skolen fangede hans interesse. -¬†Det betyder meget for mig, jeg ville ikke have v√¶ret lige s√• interesseret¬†i den her skole, hvis der ikke havde v√¶ret IT, fort√¶ller Jacob Emil Andersen, der oprindeligt stammer fra Aalborg, til TV2 Nord. En af dem, han viser rundt til Efterskolernes dag, er Isabella Kristensen, der g√•r i skole i Hune. Hun er p√• jagt efter noget helt specielt. -¬†Helt sikkert dans, springgymnastik og fitness med noget puls, forklarer Isabella Kristensen til TV2 Nord. Netop efterskolernes specialisering er en af grundene til, at rekordmange v√¶lger at bruge et √•r v√¶k fra familien i 8.-, 9.- eller 10.-klasse. De s√¶rlige linjefag har man flere af p√• Halvorsminde Efterskole. Jern og metal, arbejde med tr√¶ og vinterbadning er blot nogle af de aktiviteter, eleverne kan st√∏de ind i p√• de forskellige linjefag, som skolen tilbyder. Men efterskolerne skal ogs√• huske at have fokus p√• den¬†faglighe kvalitet,¬†lyder det fra forstanderen. -¬†Vi skal v√¶re skarpe p√• nogle nicheprodukter og nogle linjer med noget god kvalitet. S√• skal vi ogs√• lave god skole, fort√¶ller¬†forstander p√• Halvorsminde Efterskole, Jens Beermann, til TV2 Nord. Han bliver bakket op af sin kollega fra H√∏rby Efterskole ved S√¶by omkring 30 kilometer fra Halvorsminde. - N√•r man laver sit valgfagsudbud, skal det ikke v√¶re tilf√¶ldigt. Man skal ikke t√¶nke, at ‚Äôdet er smart! Det m√• tr√¶kke elever, det her!‚Äô Der skal v√¶re en velovervejet refleksion i forhold til, om det passer ind i det, vi gerne vil som skole,, siger forstander p√• H√∏rby Efterskole, Mogens Vesterg√•rd, til TV2 Nord. Alene i Nordjylland gik mere end 2.000 elever p√• efterskole i skole√•ret 2018-2019. B√•de Halvorsminde Efterskole og H√∏rby Skole har plads til 130 elever. Og noget tyder p√•, at der i hvert fald er sikret en ny¬†elev til n√¶ste skole√•r efter dagens √•bent hus. -¬†Jeg synes at det ser sp√¶ndende ud, og jeg har endnu mere lyst til at g√• her nu, siger Isabella Kristensen.",
  "target_text": "S√∏ndag inviterede efterskoler landet over potentielle nye elever inden for. Efterskolerne specialiserer sig for at tiltr√¶kke elever, men den gode faglighed m√• ikke blive glemt, lyder det fra nordjyske forstandere."
}
```
```json
{
  "text": "Efter en nat med spejl glatte veje i Nordjylland melder Nordjyllands Politi om en helt problemfri morgen.¬†Selvom politikredse i TV2 Nords sendeomr√•de melder om en rolig nat uden st√∏rre uheld, s√•¬†kan de bilister, der skal af sted l√∏rdag morgen godt forvente¬†lidt l√¶ngere rejsetid. Der er nemlig stadig glatte veje, og der er faldet en del sne i Nordjylland.¬†Saltvogne og sneplove har allerede v√¶ret p√• vejene, og Politiet opfordre forsat bilisterne til at k√∏re forsigtigt ude p√• de snefyldte veje.",
  "target_text": "Nordjyllands Politi melder om en stille morgen trods glatte veje og stort snefald i nat."
}
```
```json
{
  "text": "Det var meget t√¶t p√• at g√• galt for en 10-√•rig tysk dreng onsdag eftermiddag. Klokken 15:55 modtog alarmcentralen et opkald om en drengen, der var begravet i sand ved Vorup√∏r Strand. - Nogle b√∏rn legede p√• stranden, og her har de s√• gravet et hul ind i klitten. Det er s√• det, der er kollapset omkring drengen, fort√¶ller vagtchef Carsten Henriksen ved Midt- og Vestjyllands Politi. Det vides ikke pr√¶cist, hvor meget sand der v√¶ltede ned over barnet, men det var nok til, at drengen ikke selv kunne komme fri. De tilstedev√¶rende p√• stranden m√•tte grave ham fri. Han var¬†helt begravet i sand i omkring fem minutter. - Der var en tysk l√¶ge p√• stranden, der kunne give f√∏rstehj√¶lp, indtil ambulancen kunne komme frem, fort√¶ller vagtchefen. Drengen kom sig hurtigt og har det godt, men blev alligevel k√∏rt til tjek p√• Aalborg Sygehus.",
  "target_text": "B√∏rn p√• Vorup√∏r Strand havde gravet et hul ind i klitterne, som kollapsede omkring en 10-√•rig dreng."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  F√∏lgende er nyhedsartikler med tilh√∏rende resum√©er.
  ```
- Base prompt template:
  ```
  Nyhedsartikel: {text}
  Resum√©: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Nyhedsartikel: {text}

  Skriv et resum√© af ovenst√•ende artikel.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset nordjylland-news
```
