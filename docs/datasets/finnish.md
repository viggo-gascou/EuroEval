# üá´üáÆ Finnish

This is an overview of all the datasets used in the Finnish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### ScandiSent-fi

This dataset consists of reviews from Trustpilot and was published [here](https://aclanthology.org/2021.nodalida-main.42/). It is a binary sentiment classification dataset, with labels "positive" and "negative".

For the Finnish part of the dataset, there are 10,000 training samples. From these samples, we have created a 1,024 / 256 / 2,048 split for the train, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Kaikki meni niinkuin piti. Nopea toimitus.",
  "label": "positive"
}
```
```json
{
  "text": "En pid√§ t√§st√§, kun ei l√∂ydy linkki√§ mist√§ p√§√§sis heti maksamaan. En todellakaan pid√§ siit√§, ett√§ joka tieto pit√§√§ kopioida erikseen. Haluaisin p√§√§st√§ suoraan oston j√§lkeen maksamaa mobiilipankkiin. Pari laskua on j√§√§nyt t√§n takia kokonaan huomioimatta. Ja ihan turhaa.... √§rsytt√§√§ sitten se kotiin tuleva muistutuslasku.",
  "label": "negative"
}
```
```json
{
  "text": "Todella hidas toimitus, ja virheellist√§ tietoa tuotteiden saatavuudesta, paketti ja tuotteet perill√§ vasta kuukauden p√§√§st√§ tilauksesta....",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Seuraavassa on arvosteluja ja niiden tunnes√§vy, joka voi olla 'positiivinen' tai 'negatiivinen'.
  ```
- Base prompt template:
  ```
  Teksti: {text}
  Tunnes√§vy: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Teksti: {text}

  Luokittele arvostelun tunnes√§vy. Vastaa vain 'positiivinen' tai 'negatiivinen', ei muuta.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiivinen`
    - `negative` ‚û°Ô∏è `negatiivinen`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scandisent-fi
```


## Named Entity Recognition

### Turku-NER-fi

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.567/). The dataset is a manually annotated corpus built on the Universal Dependencies Finnish corpus. The corpus was created by the Turku NLP group.

The original dataset contains 12,217 / 1,364 / 1,555 samples for the training, validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. All the new splits are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "tokens": ["Suomalaiset", "vaihtoivat", "Tukholman", "Tallinnaan"],
  "labels": ["O", "O", "B-LOC", "B-LOC"]
}
```
```json
{
  "tokens": array(['Liuhto', 'nosti', 'Kreikan', 'tapauksen', 'yhteydess√§', 'esille', 'kysymyksen', 'siit√§', ',', 'miten', 'Euroopan', 'unionissa', 'yleisesti', 'sanktioidaan', 'pelis√§√§nt√∂jen', 'rikkomisesta', '.'], dtype=object),
  "labels": array(['B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Mithridates', 'oli', 'Pontoksen', 'merkitt√§vin', 'kuningas', 'ja', 'Rooman', 'valtakunnan', 'vaarallisin', 'vihollinen', 'ensimm√§isell√§', 'vuosisadalla', 'eaa.', '.'], dtype=object),
  "labels": array(['B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Seuraavassa on lauseita ja JSON-sanakirjoja, jotka sis√§lt√§v√§t annetussa lauseessa esiintyv√§t nimetyt entiteetit.
  ```
- Base prompt template:
  ```
  Lause: {text}
  Nimetyt entiteetit: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Lause: {text}

  Tunnista lauseessa esiintyv√§t nimetyt entiteetit. Tulosta ne JSON-sanakirjana, jonka avaimet ovat 'henkil√∂', 'paikka', 'organisaatio' ja 'muut'. Arvojen tulee olla listoja kyseisen tyypin nimetyist√§ entiteeteist√§ t√§sm√§lleen siin√§ muodossa kuin ne esiintyv√§t lauseessa.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `person`
    - `I-PER` ‚û°Ô∏è `person`
    - `B-LOC` ‚û°Ô∏è `sted`
    - `I-LOC` ‚û°Ô∏è `sted`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `diverse`
    - `I-MISC` ‚û°Ô∏è `diverse`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset turku-ner-fi
```


## Linguistic Acceptability

### ScaLA-fi

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Finnish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Finnish-TDT/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original dataset consists of 15,136 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Vuotta aiempaan verrattuna uusia ajoneuvoja rekister√∂itiin 17,6 prosenttia enemm√§n.",
  "label": "correct"
}
```
```json
{
  "text": "20-vuotias sai aiemmin marraskuussa 2006 Helsingin k√§r√§j√§oikeudelta 30 p√§iv√§sakkoa Ta... varastettujen vaatteiden hallussapidosta.",
  "label": "correct"
}
```
```json
{
  "text": "Kun k√§ytt√§j√§ kirjoittaa viestin, se n√§kyy k√§ytt√§j√§n k√§ytt√§j√§listassa.",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Seuraavat ovat lauseita ja ovatko ne kieliopillisesti oikein.
  ```
- Base prompt template:
  ```
  Lause: {text}
  Kieliopillisesti oikein: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Lause: {text}

  M√§√§rit√§ onko lause kieliopillisesti oikein vai ei. Vastaa 'kyll√§', jos lause on oikein, ja 'ei', jos se ei ole.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `kyll√§`
    - `incorrect` ‚û°Ô∏è `ei`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-fi
```


## Reading Comprehension

### TydiQA-fi
This question-answering dataset was published in [this paper](https://aclanthology.org/2020.tacl-1.30/). TydiQA is a multilingual dataset covering 11 typologically diverse languages with 204K question-answer pairs collected from native speakers genuinely seeking information. It was designed to evaluate models across languages with varied linguistic features and contains questions written directly in each language without translation.

The original Finnish TydiQA dataset contains 6,855 training and 782 validation samples (we use the [secondary task subset](https://huggingface.co/datasets/google-research-datasets/tydiqa/viewer/secondary_task?views%5B%5D=secondary_task_train)).  We created a 1,024 / 256 / 2,024 split, where the samples from the train and validation split are sampled from the original train and validation splits, respectively. The test set consists of the remaining samples from the original validation split + additional samples from the original train split.

Here are a few examples from the training split:

```json
{
  "question": "Kuka n√§ytteli Dumbledorea Harry Potter elokuvissa?",
  "context": "Dumbledorea esitt√§√§ kirjasarjasta tehdyss√§ elokuvasarjassa Richard Harris kahdessa ensimm√§isess√§ elokuvassa. Harrisin kuoltua Michael Gambon esitti hahmoa sarjan lopuissa elokuvissa.",
  "answers": {
    "text": ["Richard Harris kahdessa ensimm√§isess√§ elokuvassa. Harrisin kuoltua Michael Gambon"],
    "answer_start": [59]
  }
}

```json
{
  "question": "Milloin Cristiano Ronaldo liittyi Juventukseen?",
  "context": "Ronaldo siirtyi hein√§kuussa 2018 Juventukseen 105 miljoonalla eurolla. Sopimus on nelivuotinen, ja sen aikana h√§n tienaa verojen j√§lkeen noin 120 miljoonaa euroa.[133]",
  "answers": {
    "text": ["hein√§kuussa 2018"],
    "answer_start": [16]
  }
}
```
```json
{
  "question": "Kuka hallitsi Mithridates VI j√§lkeen?",
  "context": "Mithridates laajensi valtakuntaansa ymp√§ri Mustanmeren rantoja, ja h√§n ajautui kolmesti sotaan Rooman valtakuntaa vastaan. Ensimm√§isess√§ sodassa (89 eaa.‚Äì85 eaa.) h√§n valtasi suuren osan V√§h√§√§-Aasiaa ja Rooman valtakunnalle kuuluneet osat, jolloin h√§nen sanotaan teloittaneen 80000 roomalaista. Mithridates valtasi my√∂s Kreikan, mutta konsuli Sulla kukisti h√§nen joukkonsa vuonna 85 eaa., ja Mithridateen oli luovuttava valloituksistaan. Toinen sota (83 eaa.‚Äì81 eaa.) oli suppeampi laajuudeltaan. Kolmannessa sodassa (73 eaa.‚Äì63 eaa.) roomalaiset sotap√§√§llik√∂t Lucullus ja Pompeius kukistivat Mithridateen perusteellisesti. Mithridates surmasi tai surmautti itsens√§ jouduttuaan poikansa Farnakes II:n syrj√§ytt√§m√§ksi.",
  "answers": {
    "text": ["Farnakes II"],
    "answer_start": [687]
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Seuraavassa on tekstej√§ ja niihin liittyvi√§ kysymyksi√§ ja vastauksia.
  ```
- Base prompt template:
  ```
  Teksti: {text}
  Kysymys: {question}
  Vastaa enint√§√§n 3 sanalla: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Teksti: {text}

  Vastaa seuraavaan kysymykseen yll√§ olevasta tekstist√§ enint√§√§n 3 sanalla.

  Kysymys: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset tydiqa-fi
```


### Unofficial: BeleBele-fi

This dataset was published in [this paper](https://aclanthology.org/2024.acl-long.44/) and features multiple-choice reading comprehension questions across 122 languages.

The original dataset contains 900 unique multiple-choice reading comprehension passages and questions. From these, we use a 256 / 64 / 580 split for training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Toisin kuin muut k√§delliset, isot ihmisapinat eiv√§t en√§√§ k√§yt√§ k√§si√§√§n liikkumiseen, painon kannattelemiseen tai liikkumiseen puissa itse√§√§n heilautellen. Simpanssin k√§si ja jalka ovat samankokoisia ja -pituisia, mik√§ viittaa siihen, ett√§ k√§delle varataan painoa rystyk√§velyss√§. Ihmisen k√§si on lyhyempi kuin jalka, ja sen sormiluut ovat suoremmat. Kahden-kolmen miljoonan vuoden ik√§iset k√§siluiden fossiilit paljastavat k√§den erikoistumisessa t√§m√§n muutoksen liikkumisesta k√§yttelyyn.\nKysymys: Mik√§ seuraavista kuvaa tarkasti simpanssin sormiluita?\nVaihtoehdot:\na. Ne ovat suoremmat kuin ihmisill√§\nb. Niiden k√§det ja jalat ovat erikokoisia\nc. Niit√§ k√§ytet√§√§n painon kannattelemiseen\nd. Niit√§ k√§ytet√§√§n p√§√§asiassa k√§yttelyyn",
  "label": "c"
}
```
```json
{
  "text": "Panaman paperit on yl√§k√§site panamalaisen lakiyrityksen Mossack Fonsecan noin kymmenelle miljoonalle asiakirjalle, jotka vuodettiin lehdist√∂lle kev√§√§ll√§ 2016. Asiakirjoista selvisi, ett√§ nelj√§toista pankkia auttoi varakkaita asiakkaita piilottamaan miljardeja USA:n dollareita verojen ja muiden s√§√§ntelyjen v√§ltt√§miseksi. Brittil√§isen sanomalehden The Guardianin mukaan Deutsche Bank hallitsi t√§m√§n toteuttamiseen k√§ytetyist√§ 1 200 postilaatikkoyrityksest√§ suunnilleen kolmasosaa. Seurasi maailmanlaajuisia protesteja ja useita rikossyytteit√§, ja Islannin ja Pakistanin hallitusten johtajat kumpikin erosivat.\nKysymys: Kuka brittil√§isen lehdist√∂n v√§itteen mukaan hallinnoi monia varojen piilottamisessa k√§ytettyj√§ yrityksi√§ tekstikatkelman mukaan?\nVaihtoehdot:\na. Eri pankkien varakkaat asiakkaat\nb. Panamalainen lakiyritys\nc. Deutsche Bank\nd. Pakistanin hallitus",
  "label": "c"
}
```
```json
{
  "text": "Teksti: Sundarban on maailman suurin mangrovemets√§alue. Se ulottuu 80 kilometri√§ (50 mailia) rannikolta Bangladeshin ja Intian takamaille. Sundarban on julistettu Unescon maailmanperint√∂kohteeksi. Mets√§n Intian puolella sijaitsevaa osaa kutsutaan Sundarbanin kansallispuistoksi. Mets√§t eiv√§t kuitenkaan ole pelkki√§ mangrovesoita, vaan niihin kuuluu joitakin viimeisi√§ j√§√§nteit√§ niist√§ mahtavista viidakoista, jotka aikoinaan peittiv√§t koko Gangesin tasangon. Sundarban kattaa 3 850 neli√∂kilometrin alueen, josta noin kolmasosa on vesi- tai suoalueiden peitossa. Vuodesta 1966 asti Sundarbans on ollut villiel√§inten suojelualue. Arvioidaan, ett√§ siell√§ on nyky√§√§n 400 intiantiikeri√§ ja suunnilleen 30 000 aksishirve√§.\nKysymys: Mik√§ mets√§n osa on Intian puolella?\nVaihtoehdot:\na. Sundarbanin kansallispuisto\nb. Villiel√§inten suojelualue\nc. Maailmanperint√∂kohde\nd. Gangesin tasanko",
  "label": "a"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Seuraavat ovat monivalintakysymyksi√§ (vastauksineen).
  ```
- Base prompt template:
  ```
  Kysymys: {text}
  Vaihtoehdot:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Vastaus: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Kysymys: {text}
  Vaihtoehdot:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Vastaa yll√§ olevaan kysymykseen k√§ytt√§m√§ll√§ 'a', 'b', 'c' tai 'd', √§l√§k√§ mit√§√§n muuta.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset belebele-fi
```


## Common-sense Reasoning

### HellaSwag-fi

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The [dataset](https://huggingface.co/datasets/Finnish-NLP/hellaswag-fi-google-translate) was created by Finnish-NLP using Google Translate. The dataset is designed to
be used in EuroEval and it therefore already has a 1,024 / 256 / 2,048 split for the train, validation and test splits, respectively.

Here are a few examples from the training split:

```json
{
  "text": "[Otsikko ] Tiikkihuonekalujen tahraus [vaihe] Pyyhi lika, p√∂ly ja roskat pois. [vaihe] Voit harjata lian pois kuivalla paperipyyhkeell√§ tai liinalla. Jos puhdistettavia kohtia on sitke√§mpi√§, voit hieroa ne puhtaaksi kostealla rievulla.\nVastausvaihtoehdot:\na. [vaihe] Poista tahrat tiikist√§ pyyhkim√§ll√§ ne kuivalla talouspaperilla. [vaihe] Noudata samoja puhdistustoimenpiteit√§, joita k√§ytit tahran kanssa.\nb. Aja niiden yli puhdistusaineella, kunnes tahra on poissa. [vaihe] Kokeile puupetsin ja √∂ljyn yhdistelm√§√§.\nc. [v√§livaiheet] √Ñl√§ k√§yt√§ puhdistusaineita. Saatat vahingoittaa puuta, mutta vaikeutat varmasti v√§rj√§ysprosessia.\nd. Poista mahdollisimman paljon likaa levitt√§m√§ll√§ tahra kevyelle, p√∂rr√∂iselle liinalle tai k√§delle ja pyyhkim√§ll√§ se pois. [vaihe] K√§yt√§ hankaamiseen valkaisuainetta ja vett√§.",
  "label": "c",
}
```
```json
{
  "text": "Pieni ryhm√§ ihmisi√§ n√§hd√§√§n uimassa altaan ymp√§rill√§ ja johtaa useisiin laukauksiin, joissa uimari heitt√§√§ pallon verkkoon. Maalivahti torjuu muutaman laukauksen ja vaihtaa sitten toisen joukkuetoverinsa kanssa yleis√∂n hurraten. ihmisi√§\nVastausvaihtoehdot:\na. cheer viel√§ kerran ja palaa uimaan uima-altaan ymp√§rille.\nb. vaihda jatkuvasti pois ja johtaa siihen, ett√§ yksi joukkue voittaa ja juhlii kaikki yhdess√§ vedess√§.\nc. Curra ja hypp√§√§ vuorotellen yl√∂s ja eteenp√§in pelaamalla biljardia.\nd. ensimm√§inen video, jossa muut joukkuetoverit sukeltavat altaaseen ja hypp√§√§v√§t yl√∂s ja alas ponnahduslaudalla.",
  "label": "b",
}
```
```json
{
  "text": "Kahden ihmisen n√§hd√§√§n k√§velev√§n p√∂yt√§jalkapallop√∂yd√§n ymp√§rill√§ pelaamassa. ihmisi√§\nVastausvaihtoehdot:\na. pit√§k√§√§ kupit yl√∂s ja alakaa pelata peli√§ ja ly√∂d√§ toisianne.\nb. Tartu sauvoista ja ly√∂ palloa p√∂yd√§n ymp√§rill√§.\nc. Jatka k√§velemist√§ ja yksi henkil√∂ ly√∂ pallon verkon yli.\nd. siirr√§ ymp√§ri p√∂yt√§√§ heitt√§en palloa ymp√§riins√§, kun ihmiset katselevat sivuilla.",
  "label": "b",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Seuraavat ovat monivalintakysymyksi√§ (vastauksineen).
  ```
- Base prompt template:
  ```
  Kysymys: {text}
  Vastausvaihtoehdot:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Vastaus: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Kysymys: {text}
  Vastausvaihtoehdot:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Vastaa yll√§ olevaan kysymykseen k√§ytt√§m√§ll√§ 'a', 'b', 'c' tai 'd', √§l√§k√§ mit√§√§n muuta.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset hellaswag-fi
```


## Summarization

### XLSum-fi

This dataset is a machine translation of the XL-Sum dataset, which was published in [this paper](https://aclanthology.org/2021.findings-acl.413/). [TurkuNLP](https://huggingface.co/datasets/TurkuNLP) has translated the dataset to Finnish using DeepL.

The original Finnish XL-Sum dataset contains 54,966 / 1,803 / 1,791 training, validation and test samples, respectively. We use 1,024 / 256 / 2,048 samples for our training, validation and test splits, respectively. The new training and validation splits are subsets of the original splits. The test split is the same as the original test split + additional samples from the original validation split.

Here are a few examples from the training split:

```json
{
  "text": "Poliisi kutsuttiin Century Wharfiin keskiviikkona noin kello 14:15 GMT. 66-vuotias mies on pid√§tetty murhasta ep√§iltyn√§, ja h√§nt√§ pidet√§√§n vangittuna. Etel√§-Walesin poliisi ilmoitti, ett√§ se siirt√§√§ asian vapaaehtoisesti riippumattoman poliisin valituslautakunnan k√§sitelt√§v√§ksi.",
  "target_text": "Murhatutkinta on aloitettu sen j√§lkeen, kun 65-vuotiaan naisen ruumis l√∂ytyi Cardiff Bayn asunnosta."
}
```
```json
{
  "text": "Yritys on nimitt√§nyt KPMG:n tarkastelemaan uudelleenj√§rjestelyvaihtoehtoja sen j√§lkeen, kun paikallisviranomaisten menojen leikkaukset heikensiv√§t sen liiketoimintan√§kymi√§. Southern tarjoaa hoitoa yli 31 000 ihmiselle, ja suurin osa rahoituksesta tulee NHS:lt√§ ja kunnilta. Yrityksen mukaan budjettileikkaukset merkitsiv√§t sit√§, ett√§ sen vuokrataakka oli 'kest√§m√§t√∂n'. Southern kertoi keskustelevansa vuokranantajien kanssa uudelleenj√§rjestelyst√§ ja varoitti my√∂s, ett√§ se oli vaarassa j√§tt√§√§ velkansa maksamatta. 'Yhti√∂n lainanantajat ovat tietoisia uhkaavasta pankkikovenanttirikkomuksesta, mutta ne tukevat edelleen t√§ysin toimia, joihin yhti√∂ ryhtyy ongelmiensa ratkaisemiseksi', Southern sanoi lausunnossaan. Yhti√∂ vahvisti my√∂s, ettei se en√§√§ keskustele mahdollisten ostajien kanssa. 'Hallitus katsoo, ett√§ yksik√§√§n n√§ist√§ ehdotuksista ei todenn√§k√∂isesti johda siihen, ett√§ l√§hitulevaisuudessa teht√§isiin mielek√§s tarjous, ja se on p√§√§tt√§nyt olla jatkamatta niiden k√§sittely√§', Southern totesi. Southernin osakkeet, joiden arvo oli 606 pence√§ vuonna 2007, olivat keskip√§iv√§ll√§ 6,3 penni√§.",
  "target_text": "Yhdistyneen kuningaskunnan suurimman hoivakotien yll√§pit√§j√§n Southern Cross Healthcaren osakkeet ovat romahtaneet 60 prosenttia, kun on uutisoitu, ett√§ taloudelliset ongelmat ovat lis√§√§ntym√§ss√§."
}
```
```json
{
  "text": "Pohjois-Walesin palo- ja pelastusviranomainen vahvisti maanantaina talousarvionsa vuosiksi 2015-16. Viranomainen on suostunut leikkaamaan nelj√§ johtoteht√§v√§√§, leikkaamaan joitakin palveluja ja k√§ytt√§m√§√§n vararahastoa, jotta se voi hyv√§ksy√§ 32,1 miljoonan punnan talousarvionsa. On pel√§tty, ett√§ sadat palomiehet voivat l√§hte√§ seuraavien viiden vuoden aikana teht√§vien budjettileikkausten seurauksena.",
  "target_text": "Pohjois-Walesin palomiehet lopettavat suurten el√§inten pelastamisen ja v√§hent√§v√§t v√§√§rien h√§lytysten m√§√§r√§√§, jotta talous saataisiin tasapainoon."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  Seuraavassa on artikkeleita ja niihin liittyvi√§ tiivistelmi√§.
  ```
- Base prompt template:
  ```
  Uutisartikkeli: {text}
  Tiivistelm√§: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Uutisartikkeli: {text}

  Kirjoita tiivistelm√§ yll√§ olevasta artikkelista.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset xlsum-fi
```
