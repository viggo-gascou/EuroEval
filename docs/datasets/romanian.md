# ğŸ‡·ğŸ‡´ Romanian

This is an overview of all the datasets used in the Romanian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### RoSent

This dataset was first published in [this repository](https://github.com/katakonst/sentiment-analysis-tensorflow)
and consists of reviews from yelp and imdb.

The original dataset contains 17,941 / 11,005 samples for the training and test splits,
respectively. We use 1,024 / 256 / 2,048 samples for our training,
validation and test splits, respectively. The train and test splits are subsets of
the original splits, while the validation split is created from the training split.

Here are a few examples from the training split:

```json
{
  "text": "Nu imi place telefonul",
  "label": "negative"
}
```

```json
{
  "text": "acest film este de departe cel mai rau film realizat vreodata. daca trebuie sa creezi un film care sa-l pretuiasca pe tipul care il interpreteaza pe lars in greii de greu decat sa nu faca filmul nenorocit. trebuie sa spun ca as putea sa ma uit la leprechaun in spatiu de 6 ori inainte de a putea urmari trailerul pentru acest pos al unui film. adam sandler ar trebui sa fie restrictionat de la orice film dupa aceasta rusine. vizionarea acestui film este ca un amestec de ascultare de cher si de buna voie a pune pula intr-un blender. oricine cu jumatate dintr-o celula creierului isi va da seama ca acest film nu merita un ban. daca as avea un dolar in plus si ar fi trebuit sa-l cheltuiesc, l-as da fundatiei lorraina bobbitt de sprijin inainte de a cumpara acest film.",
  "label": "negative"
}
```

```json
{
  "text": "in lumea de astazi a fabricarii digitale, nu exista un computer decat poate inlocui actorul si scriitorul. din pacate, acest tip de film \"personalizat\" este mult prea rar in aceste zile. performanta lui duvall, precum si james earl jones sunt credinciosi asteptarilor mari ale audientei. ma intreb daca acest film a fost facut pentru televiziune? are o personalitate \"apropiata\" personala pentru naratiune. este subevaluat faptul ca performantele sunt toate remarcabile. singurul lucru care o pastreaza de a fi o cinematografie masterpiece este lipsa unui mare cinematograf, dar pozele frumoase nu sunt totul. cum poate talentul ca jones si duvall sa continue sa produca o astfel de munca amenda intr-o epoca in care actorii prezinta pentru digitizare?",
  "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  UrmeazÄƒ documentele È™i sentimentul acestora, care poate fi pozitiv, neutru sau negativ.
  ```

- Base prompt template:

  ```text
  Document: {text}
  Sentiment: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Document: {text}

  ClasificaÈ›i sentimentul documentului. RÄƒspundeÈ›i cu pozitiv, neutru sau negativ, È™i nimic altceva.
  ```

- Label mapping:
  - `positive` â¡ï¸ `pozitiv`
  - `negative` â¡ï¸ `negativ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset ro-sent
```

## Named Entity Recognition

### RoNEC

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.546/).
The sentences have been extracted from a copy-right free newspaper,
covering several styles.

The original dataset consists of 9,000 / 1,330 / 2,000 samples for the
training, validation, and test splits, respectively. We use 1,024 / 256 / 2,048
samples for our training, validation and test splits, respectively. The training
and validation splits are subsets of the original splits, while the test split is
created using additional samples from the validation split.

Here are a few examples from the training split:

```json
{
    "tokens": ["Ãn", "secolele", "al", "XVII", "-lea", "È™i", "al", "XVIII", "-lea", ",", "acestea", "erau", ":", "Conseil", "d'en", "haut", "(", "â€", "Ãnaltul", "Consiliu", "â€", ")", "-", "format", "din", "rege", ",", "prinÈ›ul", "moÈ™tenitor", "(", "â€", "le", "dauphin", "â€", ")", ",", "cancelarul", ",", "controlorul", "general", "de", "finanÈ›e", "È™i", "din", "secretarul", "de", "stat", "responsabil", "cu", "afacerile", "externe", "."],
    "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-PER", "O", "B-PER", "O", "O", "O", "O", "O", "O", "O", "O", "B-PER", "O", "B-PER", "O", "O", "O", "O", "O", "B-PER", "O", "O", "O", "O", "O", "O", "O"]
}
```

```json
{
    "tokens": ["DupÄƒ", "ce", "am", "trecut", "de", "ObÃ¢rÈ™ia-CloÈ™ani", "(", "localitate", "renumitÄƒ", "datoritÄƒ", "PeÈ™terii", "CloÈ™ani", ",", "Ã®n", "interiorul", "cÄƒreia", ",", "Ã®n", "1961", ",", "s-", "a", "Ã®nfiinÈ›at", "prima", "StaÈ›iune", "de", "cercetÄƒri", "speologice", "din", "RomÃ¢nia", ")", ",", "urcÄƒm", "la", "CumpÄƒna", "Apelor", ",", "de", "unde", "coborÃ¢m", "brÃ¢ul", "drumului", "Ã®n", "serpentine", "strÃ¢mte", ",", "pÃ¢nÄƒ", "Ã®n", "Valea", "Cernei", "."],
    "labels": ["O", "O", "O", "O", "O", "B-LOC", "O", "O", "O", "O", "B-MISC", "I-MISC", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-LOC", "O", "O", "O", "O", "B-MISC", "I-MISC", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-MISC", "I-MISC", "O"]
}
```

```json
{
    "tokens": ["La", "data", "de", "26", "octombrie", "1994", ",", "È™i-", "a", "susÈ›inut", "teza", "de", "doctorat", "Ã®n", "limba", "francezÄƒ", ",", "cu", "denumirea", "de", "La", "de", "l'homme", "la", "du", "Dumitru", "StÄƒniloae", "(", ")", ".", "Cartea", "a", "fost", "publicatÄƒ", "la", "Editura", "Trinitas", "din", "IaÈ™i", ",", "Ã®n", "2003", ",", "cu", "prilejul", "â€", "Anului", "StÄƒniloae", "â€", "(", "100", "ani", "de", "la", "naÈ™tere", "È™i", "10", "de", "la", "trecerea", "sa", "la", "cele", "veÈ™nice", ")", "."],
    "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "O", "B-LOC", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Mai jos sunt propoziÈ›ii È™i dicÈ›ionare JSON cu entitÄƒÈ›ile numite
  care apar Ã®n propoziÈ›ia datÄƒ.
  ```

- Base prompt template:

  ```text
  PropoziÈ›ie: {text}
  EntitÄƒÈ›i numite: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  PropoziÈ›ie: {text}

  IdentificÄƒ entitÄƒÈ›ile numite din propoziÈ›ie. Ar trebui sÄƒ le enumeri
  ca un dicÈ›ionar JSON cu cheile {labels_str}. Valorile cheilor ar
  trebui sÄƒ fie liste de entitÄƒÈ›i numite de tipul respectiv, exact
  cum apar Ã®n propoziÈ›ie.
  ```

- Label mapping:
  - `B-PER` â¡ï¸ `persoanÄƒ`
  - `I-PER` â¡ï¸ `persoanÄƒ`
  - `B-LOC` â¡ï¸ `locaÈ›ie`
  - `I-LOC` â¡ï¸ `locaÈ›ie`
  - `B-ORG` â¡ï¸ `organizaÈ›ie`
  - `I-ORG` â¡ï¸ `organizaÈ›ie`
  - `B-MISC` â¡ï¸ `diverse`
  - `I-MISC` â¡ï¸ `diverse`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset ronec
```

## Linguistic Acceptability

### ScaLA-ro

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Romanian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Romanian-RRT) by assuming that
the documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Era o fantomÄƒ singuraticÄƒ, rostind un adevÄƒr pe care nimeni nu avea sÄƒ -l audÄƒ vreodatÄƒ.",
    "label": "correct"
}
```

```json
{
    "text": "Pe multe locuri avem apoi dovezi de o solicitudine deosebitÄƒ, nu numai pentru paza pÄƒdurilor, dar È™i pentru nevoile locuitorilor sÄƒteni.",
    "label": "correct"
}
```

```json
{
    "text": "DacÄƒ experienÈ›a nu ne- a reuÈ™it Ã®nsÄƒ, este numai numai È™i din pricina timpului urÃ¢t de afarÄƒ.",
    "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  UrmÄƒtoarele sunt fraze È™i dacÄƒ sunt gramatical corecte.
  ```

- Base prompt template:

  ```text
  Fraza: {text}
  Gramatical corect: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Fraza: {text}

  StabiliÈ›i dacÄƒ fraza este gramatical corectÄƒ sau nu. RÄƒspundeÈ›i cu 'da' dacÄƒ este corectÄƒ, È™i cu 'nu' dacÄƒ nu este corectÄƒ. RÄƒspundeÈ›i doar cu acest cuvÃ¢nt, È™i nimic altceva.
  ```

- Label mapping:
  - `correct` â¡ï¸ `da`
  - `incorrect` â¡ï¸ `nu`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-ro
```

## Reading Comprehension

### MultiWikiQA-ro

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "Cornel BrahaÈ™, pe numele real Ionel ViÈ›u (n. 23 mai 1950, Poiana, GalaÈ›i â€“ d. 23 noiembrie 2005, BrÄƒhÄƒÈ™eÈ™ti, GalaÈ›i), a fost scriitor È™i deputat romÃ¢n Ã®n legislatura 1992-1996, ales Ã®n municipiul BucureÈ™ti pe listele PUNR.\n\nBiografie\nA fost membru al Uniunii Scriitorilor din RomÃ¢nia. \n\nA scris nouÄƒ volume de poezie, trei romane-document, o carte de reportaj, douÄƒ romane È™i un volum de reportaj-document. \n\nActivitate politicÄƒ/FuncÈ›ii: \n membru PUNR (1990-1994, exclus), apoi Partidul Dreapta RomÃ¢neascÄƒ (din 1995) si PPR;\n deputat PUNR de BucureÈ™ti (27.09.1992-3.11.1996);\n vicepreÈ™edinte al PUNR (3.10.1992) È™i preÈ™edinte al filialei BucureÈ™ti (1992-9.11.1994);\n purtÄƒtor de cuvÃ¢nt al PUNR (eliberat la 7.09.1994);\n secretar executiv al Partidului Dreapta RomÃ¢neascÄƒ (1995-2000);\n vicepreÈ™edinte al PPR (3.02.2000)\n\nOpera\nPÃ¢nÄƒ la capÄƒt È™i mai departe (roman-document)\n53 de poeme de dragoste È™i speranÈ›Äƒ\nPoezii foarte frumoase\nSfÃ¢rÈ™it de vÃ¢nÄƒtoare\nPenultimele poeme de dragoste\nPoezii din capul meu\nÃntors\nDespre morÈ›i numai de bine (reportaj-document)\nClasa muncitoare - clasa deschisÄƒ (roman Ã®n probe)\nMocÄƒneÈ™ti. Oamenii dracului\nMorÈ›ii nu mai È™tiu drumul cÄƒtre casÄƒ (roman, Ed. MilitarÄƒ 1990)\nAnno Domini - 2004 \nLaptus Vulgata\nJurnal dactilografiat (1985-1989)\nPoezii fÄƒrÄƒ mijloace\n\nNaÈ™teri Ã®n 1950\nDecese Ã®n 2005\nDeputaÈ›i romÃ¢ni 1992-1996\nScriitori romÃ¢ni din secolul al XX-lea\nPoliticieni romÃ¢ni din secolul al XX-lea\nScriitori romÃ¢ni din secolul al XXI-lea\nPoliticieni romÃ¢ni din secolul al XXI-lea\nMembri ai Uniunii Scriitorilor din RomÃ¢nia\nRomÃ¢ni cunoscuÈ›i sub pseudonimele folosite\nPoeÈ›i romÃ¢ni din secolul al XX-lea\nPoeÈ›i romÃ¢ni din secolul al XXI-lea\nMembri ai PUNR\nScriitori cunoscuÈ›i sub pseudonimele folosite",
    "question": "Cum se numeÈ™te romanul pe care Cornel BrahaÈ™ l-a publicat Ã®n anul 1990 la Editura MilitarÄƒ?",
    "answers": {
        "answer_start": [1136],
        "text": ["MorÈ›ii nu mai È™tiu drumul cÄƒtre casÄƒ"]
    }
}
```

```json
{
    "context": "Gerardus Mercator () a fost un cartograf, geograf È™i matematician flamand de renume din RenaÈ™tere. Acest nume este latinizat, un obicei pe atunci foarte rÄƒspÃ¢ndit; numele sÄƒu real Ã®n germanÄƒ a fost Gerhard Kremer (â€Kremerâ€ Ã®nseamnÄƒ â€negustorâ€). S-a nÄƒscut la 5 martie 1512 la Rupelmonde, Flandra, È™i a murit la 2 decembrie 1594 Ã®n Duisburg, Germania. A fost considerat un  \"Ptolemeu contemporan\".\n\nMercator se considera cercetÄƒtor cosmograf care nu e nevoit sÄƒ vÃ¢ndÄƒ hÄƒrÈ›i. De la el au rÄƒmas doar 5 hÄƒrÈ›i, pÄƒstrate Ã®n Muzeul de istorie din Duisburg. Ãn anul 1562 realizeazÄƒ prima hartÄƒ a Europei, care este una din hÄƒrÈ›ile atlasului sÄƒu. Numele È™i l-a schimbat Ã®n perioada cÃ¢nd era la Universitatea Essen-Duisburg.\n\nRealizÄƒri \n\n 1530 devine \"Magister\" la \"Universitatea catolicÄƒ\" din Leuven\n 1537 Ã®nsÄƒrcineazÄƒ pe meÈ™teÈ™ugarul Gaspard van der Heyden sÄƒ-i confecÈ›ioneze globul terestru, È™i bolta cerului\n 1537 Harta \"PÄƒmÃ¢ntului sfÃ¢nt\"\n 1538 o hartÄƒ micÄƒ de proiecÈ›ie Ã®n formÄƒ de inimÄƒ a lumii, È™i o hartÄƒ de perete a Flandrei\n 1540 publicÄƒ cartea  Literarum latinarum, quas italicas, cursoriasque vocant, scribendarum ratio, (pe lemn)\n 1541 Ã®È™i continuÄƒ cercetÄƒrile de proiecÈ›ie a globului pe o hartÄƒ (plan), are probleme  cu biserica catolicÄƒ (acuzat de erezie)\n 1551 realizeazÄƒ un nou glob pÄƒmÃ¢ntesc È™i unul al boltei cereÈ™ti\n 1552 urmÄƒrit de inchiziÈ›ie se refugiazÄƒ cu toatÄƒ familia la Duisburg, principatul JÃ¼lich-Kleve-Berg, prinÈ›ul  Wilhelm der Reiche fiind sub influenÈ›a humanistului Erasmus von Rotterdam\n 1554 Realizarea lui cea mai valoroasÄƒ este \"ProiecÈ›ia Mercator\", o proiecÈ›ie a globului terestru pe un plan (hartÄƒ). AceastÄƒ proiecÈ›ie redÄƒ fidel unghiurile, fiind prin aceasta de importanÈ›Äƒ majorÄƒ pentru navigaÈ›ia pe PÄƒmÃ¢nt.\n 1559 - 1562 predÄƒ matematicÄƒ È™i cosmologie la Gimnaziul din Duisburg\n 1563 este numit de  Wilhelm der Reiche cartograf princiar\n 1562 Sub Ã®ndrumÄƒrile lui Johannes Corputius, Ã®ntocmeÈ™te o hartÄƒ exactÄƒ a Duisburgului\n 1594 moare ca un om respectat È™i bogat, fiind Ã®ngropat Ã®n cimitirul bisericii \"Salvator\" din Duisburg.\n\nNote\n\nBibliografie\n\nLegÄƒturi\xa0externe\n\n Cartographic images of maps and globes \nMercator\'s maps at the Eran Laor Cartographic Collection, the National Library of Israel\n\nNaÈ™teri Ã®n 1512\nDecese Ã®n 1594\nExploratori belgieni\nCartografi flamanzi\nPerioada Marilor descoperiri\nIstoria navigaÈ›iei\nEponime ale craterelor de pe LunÄƒ\nEponime ale asteroizilor",
    "question": "Ãn ce an s-a nÄƒscut Gerardus Mercator?",
    "answers": {
        "answer_start": [259],
        "text": ["5 martie 1512"]
    }
}
```

```json
{
    "context": "Un cod de aeroport ICAO sau un identificator de locaÈ›ie ICAO este un cod alfanumeric, format din patru litere, care desemneazÄƒ fiecare din aeroporturile din lume.  Aceste coduri au fost definite de International Civil Aviation Organization È™i au fost publicate Ã®n documentul ICAO 7910: Location Indicators ().\n\nCodurile ICAO sunt folosite Ã®n controlul traficului aerian È™i Ã®n operÄƒrile liniilor aeriene cum ar fi planificarea zborurilor.  Ele nu sunt acelaÈ™i lucru cu codurile IATA, Ã®ntÃ¢lnite de publicul obiÈ™nuit È™i folosite de cÄƒtre companiile aeriene Ã®n orarele zborurilor, rezervÄƒri È™i operaÈ›iile legate de bagaje.  Codurile ICAO sunt folosite de asemenea pentru identificarea altor locaÈ›ii precum staÈ›ii meteo, staÈ›ii internaÈ›ionale de servicii ale zborurilor sau centre de control al zonelor, fie cÄƒ acestea sunt amplasate sau nu Ã®n aeroporturi.\n\nSpre deosebire de codurile IATA, codurile ICAO au o structurÄƒ regionalÄƒ la bazÄƒ, astfel Ã®ncÃ¢t ele nu sunt duplicate ci identifica un singur aeroport.  Ãn general, prima literÄƒ alocatÄƒ dupÄƒ continent È™i reprezintÄƒ o È›arÄƒ sau un grup de È›Äƒri de pe acel continent.  A doua literÄƒ Ã®n general reprezintÄƒ o È›arÄƒ din acea regiune, iar celelate douÄƒ litere rÄƒmase sunt folosite la identificarea fiecÄƒrui aeroport.  ExcepÈ›iile de la aceastÄƒ regulÄƒ sunt È›Äƒrile foarte Ã®ntinse care au coduri de È›arÄƒ formate dintr-o singurÄƒ literÄƒ, iar celelalte trei litere care rÄƒmÃ¢n desemneazÄƒ aeroportul.\n\nÃn zona Ã®ntinsÄƒ formatÄƒ de Statele Unite È™i Canada, celor mai multor aeroporturi li se asociazÄƒ codurile de trei litere IATA, care sunt aceleaÈ™i cu codurile lor ICAO, Ã®nsÄƒ fÄƒrÄƒ litera K sau C de la Ã®nceput, d.e., YYC È™i CYYC (Calgary International Airport, Calgary, Alberta), IAD È™i KIAD (Dulles International Airport, Chantilly, Virginia).  Aceste coduri nu trebuie confundate cu semnalele de apel pentru radio sau pentru televiziune, chiar dacÄƒ ambele È›Äƒri folosesc semnale de apel de formate din patru litere care Ã®ncep cu aceste litere.\n\nTotuÈ™i, fiindcÄƒ Alaska, Hawaii È™i alte teritorii din Statele Unite au propriile prefixe ICAO formate din douÄƒ litere, situaÈ›ia pentru ele este similarÄƒ altor È›Äƒri mici, iar codurile ICAO ale aeroporturilor lor sunt Ã®n general diferite de identificatoarele FAA/IATA formate din trei litere.  De exemplu, Hilo International Airport (PHTO comparativ cu ITO) È™i Juneau International Airport (PAJN comparativ cu JNU).\n\nZZZZ este un cod special care se foloseÈ™te atunci cÃ¢nd nu existÄƒ nici un cod ICAO pentru aeroport, È™i este folosit de obicei Ã®n planurile de zbor.\n\nAeroportul InternaÈ›ional Henri CoandÄƒ din Otopeni are codul LROP, iar Aeroportul InternaÈ›ional Aurel Vlaicu de la BÄƒneasa are codul LRBS  .\n\nPrefixuri\n\nVezi È™i\nListÄƒ de aeroporturi dupÄƒ codul ICAO\nListÄƒ de aeroporturi dupÄƒ codul IATA\nAeroport\n\nLegÄƒturi externe\nInternational Civil Aviation Organization (official site)\nICAO On-line Publications Purchasing  (official site)\nICAO 7910 - Location Indicators (online version provided by EUROCONTROL)\nCatalogue of ICAO Airfields \nICAO airport code prefixes \n\nCoduri\nAeroporturi",
    "question": "Care este codul ICAO pentru un aeroport?",
    "answers": {
        "answer_start": [66],
        "text": ["un cod alfanumeric, format din patru litere, care desemneazÄƒ fiecare din aeroporturile din lume"]
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  IatÄƒ texte cu Ã®ntrebÄƒri È™i rÄƒspunsuri Ã®nsoÈ›ite.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Ãntrebare: {question}
  RÄƒspuns de maxim 3 cuvinte:
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  RÄƒspunde la urmÄƒtoarea Ã®ntrebare referitoare la textul de mai sus folosind maxim 3 cuvinte.

  Ãntrebare: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-ro
```

## Knowledge

### Global-MMLU-ro

Global-MMLU is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Romanian was done by the [Cohere Labs Community](https://cohere.com/research).

The original full dataset consists of 285 / 14,042 samples for
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total).
The validation set is sampled from the dev set, and the new train and test
sets are sampled from the test set.

Here are a few examples from the training split:

```json
{
  "text": "O cumpÄƒrÄƒtoare a suferit rÄƒni la spate È™i la picioare cÃ¢nd a alunecat pe o bucatÄƒ de covor, pe un hol care face legÄƒtura Ã®ntre un magazin universal È™i o cantinÄƒ. CumpÄƒrÄƒtorul a intentat un proces Ã®mpotriva proprietarului Ã®ntregii clÄƒdiri. Proprietarul a susÈ›inut cÄƒ, de cÃ¢nd a Ã®nchiriat cantina, nu a mai pÄƒstrat niciun control asupra holului de legÄƒturÄƒ. Ãn cazul Ã®n care cumpÄƒrÄƒtorul oferÄƒ Ã®n dovadÄƒ faptul cÄƒ la douÄƒ zile dupÄƒ accident, proprietarul a pus din nou covorul de pe hol, instanÈ›a ar trebui sÄƒ stabileascÄƒ cÄƒ probele sunt\nOpÈ›iuni:\na. admisibil, deoarece este relevant pentru problema cunoaÈ™terii de cÄƒtre proprietar a stÄƒrii nesigure.\nb. admisibilÄƒ, deoarece aratÄƒ cÄƒ proprietarul È™i-a pÄƒstrat proprietatea È™i controlul.\nc. inadmisibil, deoarece aratÄƒ reparaÈ›ie ulterioarÄƒ, ceea ce este contrar ordinii publice.\nd. inadmisibil, deoarece probele sunt irelevante pentru accident.",
  "label": "b",
}
```

```json
{
  "text": "Pentru care dintre aceste douÄƒ scenarii personajul principal (care foloseÈ™te I/me/my) face ceva Ã®n mod clar greÈ™it din punct de vedere moral, conform standardelor morale obiÈ™nuite din SUA Ã®ncepÃ¢nd cu 2020? Scenariul 1 | Am pus copilul pe unghii Scenariul 2 | De obicei prefer sÄƒ rÄƒnesc oamenii Ã®n loc sÄƒ Ã®ncerc sÄƒ-i protejez.\nOpÈ›iuni:\na. GreÈ™it, greÈ™it\nb. GreÈ™it, nu greÈ™it\nc. Nu greÈ™it, greÈ™it\nd. Nu greÈ™it, nu greÈ™it",
  "label": "a",
}
```

```json
{
  "text": "Inventarul Cobb Inc. la 1 mai consta din 200 de unitÄƒÈ›i la un cost total de 1250 USD. Cobb foloseÈ™te metoda inventarierii periodice. AchiziÈ›iile pentru luna au fost dupÄƒ cum urmeazÄƒ: Data Nr. de unitÄƒÈ›i Cost unitar Cost total 4 mai 20 5,80 USD 116,00 USD 17 mai 80 5,50 USD 440,00 USD Cobb a vÃ¢ndut 10 unitÄƒÈ›i pe 14 mai pentru 120 USD. Care este costul mediu ponderat al bunurilor vÃ¢ndute al lui Cobb pentru luna mai?\nOpÈ›iuni:\na. 60,20 USD\nb. 62,10 USD\nc. 62,50 USD\nd. 65",
  "label": "a",
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  UrmÄƒtorul este un set de Ã®ntrebÄƒri cu mai multe opÈ›iuni (cu rÄƒspunsuri).
  ```

- Base prompt template:

  ```text
  Ãntrebare: {text}
  OpÈ›iuni:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  RÄƒspuns: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ãntrebare: {text}

  RÄƒspundeÈ›i la urmÄƒtoarea Ã®ntrebare folosind 'a', 'b', 'c' sau 'd', È™i nimic altceva.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset global-mmlu-ro
```

## Common-sense Reasoning

### Winogrande-ro

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Nu am putut controla umezeala aÈ™a cum am controlat ploaia, deoarece _ venea de peste tot. La ce se referÄƒ spaÈ›iul gol _?\nOpÈ›iuni:\na. umezealÄƒ\nb. ploaie",
  "label": "a"
}
```

```json
{
  "text": "Jessica a crezut cÄƒ Sandstorm este cea mai grozavÄƒ melodie scrisÄƒ vreodatÄƒ, dar Patricia o ura. _ a cumpÄƒrat un bilet la concertul de jazz. La ce se referÄƒ spaÈ›iul gol _?\nOpÈ›iuni:\na. Jessica\nb. Patricia",
  "label": "b"
}
```

```json
{
  "text": "Termostatul arÄƒta cÄƒ era cu douÄƒzeci de grade mai rece jos decÃ¢t era sus, aÈ™a cÄƒ Byron a rÄƒmas Ã®n _ pentru cÄƒ Ã®i era frig. La ce se referÄƒ spaÈ›iul gol _?\nOpÈ›iuni:\na. jos\nb. sus",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  UrmÄƒtorul este un set de Ã®ntrebÄƒri cu mai multe opÈ›iuni (cu rÄƒspunsuri).
  ```

- Base prompt template:

  ```text
  Ãntrebare: {text}
  OpÈ›iuni:
  a. {option_a}
  b. {option_b}
  RÄƒspuns: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Ãntrebare: {text}
  OpÈ›iuni:
  a. {option_a}
  b. {option_b}

  RÄƒspundeÈ›i la urmÄƒtoarea Ã®ntrebare folosind 'a' sau 'b', È™i nimic altceva.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-ro
```

## Summarisation

### SumO-ro

[The dataset](https://huggingface.co/datasets/Gabrielaaaaaa/SumO-Ro) and consists of samples
from Romanian news articles.

The original full dataset consists of 179,839 / 1,500 / 1,500 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively. The train and validation set are sampled from
the original splits, but the test set has additional samples from both the validation set.

Here are a few examples from the training split:

```json
{
  "text": "Din cauza aglomeraÈ›iei, unul dintre cele cinci centre de testare a fost Ã®nchis. AutoritÄƒÈ›ile vor sÄƒ testeze pÃ¢nÄƒ la Ã®nceputul anului È™colar 100.000 de elevi È™i cadre medicale. Testarea elevilor È™i cadrelor didactice din regiunea Madrid va costa aproximativ un milion de euro, scrie Digi 24. Spania a fost una dintre cele mai afectate È›Äƒri din Europa de epidemie Ã®n primÄƒvarÄƒ, Ã®nainte de introducerea unora dintre cele mai stricte mÄƒsuri din lume, care i-a permis sÄƒ È›inÄƒ apoi cazurile sub control. ÃnsÄƒ de cÃ¢nd izolarea a fost Ã®n totalitate ridicatÄƒ la 21 iunie, epidemia a revenit Ã®n forÈ›Äƒ, cu o explozie de cazuri legatÄƒ Ã®n special de reuniunile familiale sau de ieÈ™irile nocturne. Cel mai recent bilanÈ› al Ministerului SÄƒnÄƒtÄƒÈ›ii, publicat luni, a Ã®nregistrat 23.000 de cazuri noi de vineri È™i un total de 462.858 de cazuri detectate de la Ã®nceputul epidemiei.",
  "target_text": "Mii de cadre didactice au format cozi uriaÈ™e Ã®n Madrid, ca sÄƒ facÄƒ gratuit testul COVID. Testarea trebuie fÄƒcutÄƒ pÃ¢nÄƒ luni, iar oamenii sunt furioÈ™i cÄƒ au fost anunÈ›aÈ›i cu doar cÃ¢teva ore Ã®nainte."
}
```

```json
{
  "text": "Cuprins: Trupul neÃ®nsufleÈ›it al lui Mircea Diaconu va fi depus luni, Ã®ntre orele 12:00 È™i 16:00, la Teatrul Nottara, acolo unde apropiaÈ›ii vor putea veni sÄƒ-È™i aducÄƒ un ultim omagiu. ÃnmormÃ¢ntarea lui Mircea Diaconu va avea loc marÈ›i, la cimitirul din SÄƒftica. Mircea Diaconu era cunoscut pentru rolurile sale memorabile Ã®n filme, dar È™i pentru implicarea sa activÄƒ Ã®n viaÈ›a publicÄƒ, fiind un nume È™i Ã®n politicÄƒ. Mircea Diaconu a fost un simbol al teatrului È™i filmului romÃ¢nesc, avÃ¢nd o carierÄƒ care s-a Ã®ntins pe mai multe decenii. De asemenea, a fost un nume cunoscut Ã®n politicÄƒ, fiind ales senator È™i deputat, implicÃ¢ndu-se Ã®n multiple proiecte pentru Ã®mbunÄƒtÄƒÈ›irea vieÈ›ii culturale È™i sociale din RomÃ¢nia. Mircea Diaconu, nÄƒscut pe 24 decembrie 1949, Ã®n VlÄƒdeÈ™ti, judeÈ›ul ArgeÈ™, a fost un simbol al teatrului È™i filmului romÃ¢nesc. Mircea Diaconu a absolvit Liceul la CÃ¢mpulung Muscel Ã®n 1967 È™i IATC I.L. Caragiale din BucureÈ™ti Ã®n 1971. A debutat Ã®n 1970, la Teatrul Bulandra, cu \"Harfa de iarbÄƒ de Truman Capote. Debutul Ã®n cinematografie a avut loc Ã®n 1971, cu filmul \"Nunta de piatrÄƒ, dupÄƒ Ion AgÃ¢rbiceanu, Ã®n regia lui Dan PiÈ›a. Video: Asfalt Tango (1996), regizor Nae Caranfil",
  "target_text": "Actorul Mircea Diaconu a murit la vÃ¢rsta de 74 de ani, dupÄƒ o luptÄƒ grea cu cancerul, a anunÈ›at, sÃ¢mbÄƒtÄƒ, soÈ›ia sa, potrivit Observator. Pe 24 decembrie, cunoscutul actor Mircea Diaconu ar fi Ã®mplinit 75 de ani, Ã®nsÄƒ cancerul l-a rÄƒpus."
}
```

```json
{
  "text": "IntevenÈ›ia unui elicopter SMURD pentru salvarea unui tursit Ã®n zona \"La trei paÈ™i de moarte, MunÈ›ii FÄƒgÄƒraÈ™ului. A fost chemat Ã®n ajutor È™i elicopterul SMURD din judeÈ›ul MureÈ™, a anunÈ›at, duminicÄƒ, È™eful Salvamont Sibiu, Dan Popescu, potrivit Agerpres. \"SPJ Salvamont Sibiu È™i ArgeÈ™ intervin pentru acordarea de prim ajutor unui turist Ã®n vÃ¢rstÄƒ de 38 de ani din Cluj, care acuza o stare de greaÈ›Äƒ, vÄƒrsÄƒturi È™i este Ã®n incapacitate de deplasare. Victima se aflÄƒ Ã®n zona \' La trei paÈ™i de moarte\' din MunÈ›ii FÄƒgÄƒraÈ™. A fost alertat È™i elicopterul SMURD MureÈ™\", a precizat Popescu. SalvamontiÈ™tii din ArgeÈ™ au anunÈ›at, pe pagina oficialÄƒ de Facebook, cÄƒ elicopterul a putut prelua victima. Ei au prezentat È™i imagini de la intervenÈ›ie.",
  "target_text": "IntevenÈ›ia unui elicopter SMURD pentru salvarea unui tursit Ã®n zona \"La trei paÈ™i de moarte. SalvamontiÈ™tii din douÄƒ judeÈ›e, Sibiu È™i ArgeÈ™, au intervenit pentru salvarea unui turist din Cluj, care nu se mai putea deplasa."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:

  ```text
  Mai jos sunt articolele Ã®nsoÈ›ite de rezumate.
  ```

- Base prompt template:

  ```text
  Articol: {text}
  Rezumat: {target_text}
  ```

- Instruction-tuned prompt template:

  ```text
  Articol: {text}

  Scrie un rezumat al articolului de mai sus.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset sumo-ro
```
