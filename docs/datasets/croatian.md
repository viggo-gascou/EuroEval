# 游쇓릖 Croatian

This is an overview of all the datasets used in the Croatian part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### MMS-hr

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2306.07902).
The corpus consists of 79 manually selected datasets from over 350 datasets reported in the
scientific literature based on strict quality criteria.

The original dataset contains a single split with 77,594 Croatian samples.
We use 1,024 / 256 / 2,048 samples for our training, validation, and test splits,
respectively.
We have employed stratified sampling based on the label column from the original
dataset to ensure balanced splits.

Here are a few examples from the training split:

```json
{
    "text": "ali kako mozete biti ovako trijezni u ovo doba ajde molim vas",
    "label": "negative"
}
```

```json
{
    "text": "RT @bsimun: Thompson okupio 100 000 ljudi u 캛avoglavama. Sad 캖e valjda platiti porez. #domoljublje #DanPobjede",
    "label": "neutral"
}
```

```json
{
    "text": "\n 만sti \"El Cl치sico\" za\n \n  Luku Modri캖a\n \n bio je i najdra쬴. Real je dobio Bar칞u 3-1, a hrvatski veznjak bio je jedan od najboljih igra캜a \"kraljeva\".\n\n\n\n - Otkako sam u Madridu, meni je to djelovalo kao\n \n  najuvjerljivija demonstracija mo캖i\n \n . Bar칞a je izgledala manje mo캖no jer je Real odigrao impresivno. Meni ta pobjeda vi코e govori o snazi na코e mom캜adi, o potvrdi kako forma koju iskazujemo ve캖 osam-devet utakmica nije slu캜ajna - rekao je Luka za\n \n  SN\n \n .\n\n\n - Imali su psiholo코ku prednost zbog stanja na ljestvici i manjeg imperativa. Zato je\n \n  Realov uspjeh impresivan\n \n , tim prije 코to smo gubili 0-1 - dodao je.\n\n\n\n  Izvorni 캜lanak pro캜itajte u\n  \n   Sportskim novostima\n  \n  .\n \n\n\n Pohvalio suigra캜e\n  \n\n\n -\n \n  캛udesna utakmica\n \n cijele mom캜adi i pobjeda protiv Barcelone. Ajmo, hal치 Madrid! - napisao je Modri캖 na dru코tvenim mre쬬ma.\n  \n",
    "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Slijede dokumenti i njihova osjetila, koja mogu biti pozitivno, neutralno ili negativno.
  ```

- Base prompt template:

  ```text
  Dokument: {text}
  Osjetilo: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Dokument: {text}

  Klasificirajte osje캖aj u dokumentu. Odgovorite samo s pozitivno, neutralno, ili negativno, i ni코ta drugo.
  ```

- Label mapping:
  - `positive` 俱뫮잺 `pozitivno`
  - `neutral` 俱뫮잺 `neutralno`
  - `negative` 俱뫮잺 `negativno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mms-hr
```

## Named Entity Recognition

### WikiANN-hr

This dataset was published in [this paper](https://aclanthology.org/P17-1178/) and is
part of a cross-lingual named entity recognition framework for 282 languages from
Wikipedia. It uses silver-standard annotations transferred from English through
cross-lingual links and performs both name tagging and linking to an english Knowledge
Base.

The original full dataset consists of 10,000 / 10,000 / 10,000 samples for the training,
validation and test splits, respectively. We use 1,024 / 256 / 2,048 samples for our
training, validation and test splits, respectively. All the new splits are subsets of
the original splits.

Here are a few examples from the training split:

```json
{
    "tokens": array(["Ubrzo", "su", "uslijedile", "narud쬭e", "iz", "cijele", "Britanske", "zajednice", "naroda", "."], dtype=object),
    "labels": ["O", "O", "O", "O", "O", "O", "B-ORG", "I-ORG", "I-ORG", "O"]
}
```

```json
{
    "tokens": array(["``", "(", "Cole", "Porter", ")"], dtype=object),
    "labels": ["O", "O", "B-PER", "I-PER", "O"]
}
```

```json
{
    "tokens": array(["'", "''", "La", "Liga", "2009.", "/", "10", "."], dtype=object),
    "labels": ["O", "O", "B-ORG", "I-ORG", "O", "O", "O", "O"]
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Sljede캖e su re캜enice i JSON rje캜nici s imenicama koje se pojavljuju u re캜enicama.
  ```

- Base prompt template:

  ```text
  Re캜enica: {text}
  Imenovane entiteti: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Re캜enica: {text}

  Identificirajte imenovane entitete u re캜enici. Prika쬴te ih kao JSON rje캜nik s klju캜evima 'osoba', 'mjesto', 'organizacija' i 'razno'. Vrijednosti trebaju biti popisi imenovanih entiteta navedenog tipa, to캜no kako se pojavljuju u re캜enici.
  ```

- Label mapping:
  - `B-PER` 俱뫮잺 `osoba`
  - `I-PER` 俱뫮잺 `osoba`
  - `B-LOC` 俱뫮잺 `mjesto`
  - `I-LOC` 俱뫮잺 `mjesto`
  - `B-ORG` 俱뫮잺 `organizacija`
  - `I-ORG` 俱뫮잺 `organizacija`
  - `B-MISC` 俱뫮잺 `razno`
  - `I-MISC` 俱뫮잺 `razno`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset wikiann-hr
```

## Linguistic Acceptability

### ScaLA-hr

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Croatian Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Croatian-SET) by assuming that the
documents in the treebank are correct, and corrupting the samples to create
grammatically incorrect samples. The corruptions were done by either removing a word
from a sentence, or by swapping two neighbouring words in a sentence. To ensure that
this does indeed break the grammaticality of the sentence, a set of rules were used on
the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
    "text": "Nakon kratke intervencije, tijekom koje sam saznala kada se taj osje캖aj prvog puta pojavio i zbog 캜ega, sve je nestalo i ve캖 mjesecima 쬴vim bez optere캖enja koji me pratilo cijelog 쬴vota.",
    "label": "correct"
}
```

```json
{
    "text": "Svaki od tih sklopova, i dijelova mora biti homologiran i sukladan s ostalima.",
    "label": "incorrect"
}
```

```json
{
    "text": "Prvi me캠u njima je Laurent Blanc, koji dr쬴 Romu na 캜ekanju, a s Parkom prin캜eva povezivan je i Fabio Capello.",
    "label": "correct"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Sljede캖e su re캜enice i jesu li gramati캜ki ispravne.
  ```

- Base prompt template:

  ```text
  Re캜enica: {text}
  Gramati캜ki ispravna: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Re캜enica: {text}

  Odredite je li re캜enica gramati캜ki ispravna ili ne. Odgovorite s 'da' ako je ispravna, i s 'ne' ako nije. Odgovorite samo tom rije캜ju i ni캜im drugim.
  ```

- Label mapping:
  - `correct` 俱뫮잺 `da`
  - `incorrect` 俱뫮잺 `ne`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-hr
```

## Reading Comprehension

### MultiWikiQA-hr

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "Arkadija je pokrajina u sredi코njem dijelu Peloponeza, Gr캜ka.\n\nOsnovni podaci\nGlavni grad Arkadije je Tripoli; populacija pokrajine je 100 611 (podatci iz 2005.), na 38. mjestu u Gr캜koj; Povr코ina joj je 4419 km 코to je 캜ini 5. po veli캜ini; Gusto캖a naseljenosti je 22,8/km; sastoji se od 4 provincije, 22 op캖ine i 1 쬿panije (okruga); po코tanski broj je 22, registracijske plo캜ice s oznakom TP; slu쬭ena web stranica je www.arcadia.gr.\n\nOp캖ine\n\nPovijest\n\nGradska naselja u Arkadiji su se razvila razmjerno kasno (Mantineja, Orhomen, Tegeja). Bili su saveznici Sparte do sloma njezine hegemonije (371. pr. Kr.), otada tvore samostalan savez pod vodstvom novoosnovanog polisa Megalopola. Samostalnost saveza dokraj캜ili su Makedonci. U 3. st. pr. Kr. dio gradova u Arkadiji pristupa Ahajskom, a dio Etolskom savezu. Pod rimskom vla코캖u od 168. pr. Kr.\n\nSimbolika Arkadije\n\nPrema gr캜koj tradiciji Arkadija je postojbina Pana, domovina jednostavnih, priprostih i po코tenih ljudi (pastira). Kao simbol nepokvarena i idili캜na 쬴vota javlja se tzv. bukolska (pastirska) poezija. Obnovljena u doba renesanse pod utjecajem idili캜nog romana "Arkadija" talijanskog pisca J. Sannazzara. \n\nPo Arkadiji je ime dobila i 캜uvena knji쬹ica Akademija (Accademia degli Arcadi), osnovana 1690. g. u Rimu, a pod njenim utjecajem osnovana su i mnoga sli캜na dru코tva diljem Italije i hrvatske obale (Zadar, Split, Dubrovnik).\n\nVanjske poveznice\n\nPan-Arkadski Kongres.\nhttp://www.arcadians.gr\nSveu캜ili코te u Patrasu, Arkadia-Project.\nArkadija, Gr캜ka.\nNepoznata Arkadija.\nhttp://flyingbrick.freeyellow.com/arcadia.htm \nhttp://www.arcadianet.gr/en/\nhttp://www.tripolis.gr\n\nZemljopis Gr캜ke",
    "question": "Koji je naziv za pjesni코tvo pastira koje simbolizira neiskvareni i idili캜an 쬴vot?",
    "answers": {
        "answer_start": [1037],
        "text": ["bukolska"]
    }
}
```

```json
{
    "context": "Hans Emil Alexander Gaede (Kolberg, 19. velja캜e 1852. -  Freiburg im Breisgau, 16. rujna 1916.) je bio njema캜ki general i vojni zapovjednik. Tijekom Prvog svjetskog rata zapovijedao je Armijskim odjelom B na Zapadnom boji코tu.\n\nVojna karijera\nHans Gaede ro캠en je 19. velja캜e 1852. u Kolbergu (danas Kolobrzeg u Poljskoj). Sin je Alexandera Gaede i Emilie Franke. Gaede je u prusku vojsku stupio 1870. godine, te je sudjelovao u Prusko-francuskom ratu u kojem je i ranjen. Nakon rata poha캠a Prusku vojnu akademiju, te nakon zavr코etka iste slu쬴 u raznim vojnim jedinicama kao u i pruskom ministarstvu rata. 캛in pukovnika dostigao 1897. godine kada postaje zapovjednikom i tvr캠ave Thorn. General bojnikom je postao 1900. godine, dok je 1904. godine promaknut u 캜in general poru캜nika kada dobiva zapovjedni코tvo nad 33. pje코a캜kom divizijom smje코tenom u Metzu koji se tada nalazio u okviru Njema캜kog Carstva. Godine 1907. Gaede je stavljen na raspolaganje.\n\nPrvi svjetski rat\nNa po캜etku Prvog svjetskog rata Gaede je reaktiviran, te postaje zamjenikom zapovjednika XIV. korpusa koji je bio u sastavu 7. armije koja se nalazila pod zapovjedni코tvom Josiasa von Heeringena. U rujnu 1914. postaje zapovjednikom Armijskog odjela Gaede koji je kasnije preimenovan u Armijski odjel B koji je dr쬬o front u Gornjem Alzasu. Za zapovijedanje u borbama u Alzasu Gaede je 25. rujna 1915. godine odlikovan ordenom Pour le M칠rite. U prosincu 1915. Gaedeu je na Sveu캜ili코tu u Freiburgu dodijeljen po캜asni doktorat.\n\nSmrt\nU rujnu 1916. godine Gaede se te코ko razbolio zbog 캜ega je 3. rujna 1916. morao napustiti zapovjedni코tvo armijskog odjela. Umro je 16. rujna 1916. godine u 64. godini 쬴vota u bolnici Freiburgu im Breisgau od posljedica operacije.\n\nVanjske poveznice\n     Hans Gaede na stranici Prussianmachine.com\n     Hans Gaede na stranici Deutschland14-18.de\n\nNjema캜ki vojni zapovjednici u Prvom svjetskom ratu",
    "question": "Koju nagradu je Gaede primio 25. rujna 1915.?",
    "answers": {
        "answer_start": [1395],
        "text": ["Pour le M칠rite"]
    }
}
```

```json
{
    "context": "콯iroglavci (Enteropneusta) su u klasi캜noj sistematici 쬴votinjski razred s manje od 100 poznatih vrsta. Ubraja ih se u kojeno polusvitkovce (Hemichordata) i preko njih u drugousti (Deuterostomia), jer im se tijekom embrionalnog razvoja usta razvijaju a ne proizlaze iz "prausta", prvog otvora ranog embrionalnog 쬴votnog stadija, gastrule. Njihovo znanstveno ime zna캜i, 코to izra쬬va i tradicionalno mi코ljenje da su oni praoblik svitkovaca, u koje spadaju i kralje쬹jaci.\n\nNo, mjesto 쬴roglavaca u sistematici je danas sporno. Tako se razmatra mogu캖a srodnost 쬴roglavaca ne samo sa svitkovcima, nego i s bodljika코ima (Echinodermata) u koje spadaju na primjer zvjezda캜e (Asteroidea) i je쬴nci (Echinoidea). 캛ak se sve vi코e smatra vjerojatnijim da 쬴roglavci ne 캜ine monofiletsku skupinu, 코to zna캜i da oni nisu svi potomci istih zajedni캜kih predaka.\n\nGra캠a i izgled\nTijelo 쬴roglavaca je meko, crvoliko, i osim grube podjele na tri dijela, nesegmentirano. Veli캜inom su vrlo razli캜iti, neke vrste su duge samo nekoliko milimetara, dok druge mogu biti duge i 2,5 metra. Boja im je razli캜ita, od bijele do tamno ljubi캜aste.\n  \nMe캠u beskralje코njacima, 쬴roglavci su neobi캜ni jer imaju neke osobine koje su tipi캜ne za kralje쬹jake: \n Njihov 쬴v캜ani sustav satoji se od 쬴v캜anih vrpci koje se prote쬿 le캠nom i trbu코nom stranom 쬴votinje. U predjelu "glave" i oko crijeva ove dvije 쬴v캜ane vrpce kru쬹o su me캠usobno povezane a od njih se odvajaju 쬴v캜ane niti koje zavr코avaju u vanjskoj ko쬴. Le캠na 쬴v캜ana vrpca smje코tena je u posebnom naboru. Zbog njegovog nastanka u embrionalnom razvoju ponekad ga se smatra homolognim le캠noj mo쬯ini svitkovaca.\n 콯iroglavci imaju i do 100 쬯rijelnih pukotina koje imaju isto anatomsko porijeklo kao i 코krge kod riba. Voda koja im u캠e na usni otvor nakon zadr쬬vanja djeli캖a hrane, izlazi iz tijela kroz te pukotine.\n\nHrana, 쬴votni prostor i rasprostranjenost\n콯iroglavci se hrane na dva razli캜ita na캜ina: ili kopaju kroz sediment morskog dna, 코to zna캜i da uzimaju mulj dna i probavljaju u njemu sadr쬬n organski sadr쬬j (kao ki코ne gliste), ili filtriraju iz vode sadr쬬ne djeli캖e organske materijekao na primjer alge. Zbog toga 쬴ve uglavnom u ili neposredno ispod dijela izlo쬰nog plimi i oseci, na ili u morskom dnu (bentos) dijelom i do dubine od 5.000 metara, i tamo 캜esto 쬴ve u kanali캖ima u obliku slova U. Samo rijetke vrste 쬴ve u otvorenom moru (pelagijal). 콯iroglavci 쬴ve u svim morskim podru캜jima, od tropa pa sve do u polarna podru캜ja.\n\nRazmno쬬vanje\n콯iroglavci su odvojenih spolova, no izgledom se gotovo ne razlikuju. Iz oplo캠enog jaja코ca naj캜e코캖e se prvo razvijaju trepetljive larve vrlo sli캜ne larvama bodljika코a. Dio 쬴votnog ciklusa prije metamorfoze provodi kao plankton hrane캖i se djeli캖ima hrane koji se zadr쬰 na trepetljikama larve i od tamo se prenose do ustiju. Kod nekih vrsta razvoj se odvija direktno, bez larvenog stadija.\n\nDrugi projekti i vanjske poveznice\nTaksonomija 쬴roglavaca  (engleski)\nFilogeneza 쬴roglavaca (engleski)\n\nPolusvitkovci",
    "question": "Koliki je broj poznatih vrsta 쬴roglavaca?",
    "answers": {
        "answer_start": [75],
        "text": ["manje od 100"]
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

```text
Sljede캖i tekstovi sadr쬰 pitanja i odgovore.
```

- Base prompt template:

```text
Tekst: {text}
Pitanje: {question}
Odgovor s najvi코e 3 rije캜i:
```

- Instruction-tuned prompt template:

```text
Tekst: {text}

Odgovorite na sljede캖e pitanje o gornjem tekstu s najvi코e 3 rije캜i.

Pitanje: {question}
```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-hr
```

## Knowledge

### MMLU-hr

This dataset was published in
[this paper](https://doi.org/10.48550/arXiv.2410.08928) and is a machine
translated version of the English [MMLU dataset](https://openreview.net/forum?id=d7KBjmI3GmQ).
It features questions within 57 different topics, such as elementary mathematics, US
history, and law. DeepL was used to translate the dataset to Croatian.

The original full dataset consists of 254 / 12,338 samples for
validation and testing. These splits were merged, duplicates removed, and
new splits were created with 1,024 / 256 / 2048 samples for training, validation, and
testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Kako se odvija lateralna komunikacija u organizaciji?\nIzbori:\na. Informacije se prenose prema gore.\nb. Informacije se prenose prema dolje.\nc. Informacije su dvosmjerni proces.\nd. Informacije se prenose izme캠u razli캜itih odjela i funkcija.",
    "label": "d"
}
```

```json
{
    "text": "Kako astronomi misle da Jupiter generira svoju unutarnju toplinu?\nIzbori:\na. kroz egzotermne kemijske reakcije koje pretvaraju kemijsku potencijalnu energiju u toplinsku energiju\nb. nuklearna fuzija\nc. kontrakcijom koja mijenja gravitacijsku potencijalnu energiju u toplinsku energiju\nd. unutarnje trenje zbog njegove brze rotacije i diferencijalne rotacije",
    "label": "c"
}
```

```json
{
    "text": "Ako se parabola $y_1 = x^2 + 2x + 7$ i pravac $y_2 = 6x + b$ sijeku u samo jednoj to캜ki, koja je vrijednost $b$?\nIzbori:\na. 7\nb. 3\nc. 12\nd. 4",
    "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Sljede캖a su pitanja s vi코estrukim izborom (s odgovorima).
  ```

- Base prompt template:

  ```text
  Pitanje: {text}
  Izbori:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Pitanje: {text}

  Odgovorite na gornje pitanje koriste캖i 'a', 'b', 'c' ili 'd', i ni코ta drugo.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-hr
```

## Common-sense Reasoning

### Winogrande-hr

This dataset was published in
[this paper](https://doi.org/10.48550/arXiv.2506.19468) and is a translated
and filtered version of the English
[Winogrande dataset](https://doi.org/10.1145/3474381). DeepL was used to
translate the dataset to Croatian.

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
    "text": "Nisam mogao kontrolirati vlagu kao 코to sam kontrolirao ki코u, jer je _ dolazila odasvud. Na 코to se odnosi praznina _?\nIzbori:\na. vlaga\nb. ki코a",
    "label": "a"
}
```

```json
{
    "text": "Jessica je mislila da je Sandstorm najbolja pjesma ikad napisana, ali Patricia ju je mrzila. _ je kupila kartu za jazz koncert. Na 코to se odnosi praznina _?\nIzbori:\na. Jessica\nb. Patricia",
    "label": "b"
}
```

```json
{
    "text": "Termostat je pokazivao da je dolje dvadeset stupnjeva hladnije nego gore, pa je Byron ostao u _ jer mu je bilo hladno. Na 코to se odnosi praznina _?\nIzbori:\na. dolje\nb. gore",
    "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Sljede캖a su pitanja s vi코estrukim izborom (s odgovorima).
  ```

- Base prompt template:

  ```text
  Pitanje: {text}
  Mogu캖nosti:
  a. {option_a}
  b. {option_b}
  Odgovor: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Pitanje: {text}
  Mogu캖nosti:
  a. {option_a}
  b. {option_b}

  Odgovorite na gornje pitanje koriste캖i 'a' ili 'b', i ni코ta drugo.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-hr
```
